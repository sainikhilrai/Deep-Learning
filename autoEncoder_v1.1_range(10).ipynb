{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoEncoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sainikhilrai/Deep-Learning/blob/master/autoEncoder_v1.1_range(10).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVBNC-wEkPF5",
        "colab_type": "code",
        "outputId": "76d38614-63fa-4c2c-b185-1ce6d1fe6fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jVnUqk9kYYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OM SRI SAI RAM\n",
        "\n",
        "# Descr: Basic or experiment code to perform loss reserve prediction\n",
        "\n",
        "##############################\n",
        "# Step 1 : Reading Sample Data\n",
        "##############################\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sklearn\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
        "np.random.seed(7)\n",
        "random.seed(7)\n",
        "accident_years = np.arange(2005,2013,1)\n",
        "development_years = np.arange(0,8,1)\n",
        "triangle = np.array(([1232,946,520,722,316,165,48,14],\n",
        "                   [1469,1201,708,845, 461,235,56,18],\n",
        "                   [1652,1416,959,954,605,287,69,21],\n",
        "                   [1831,1634,1124,1087,725,314,79,24],\n",
        "                   [2074,1919,1330,1240,756,359,91,28],\n",
        "                   [2434,2263,1661,1540,909,432,109,33],\n",
        "                   [2810,2108,1544,1565,924,439,111,34],\n",
        "                   [3072,2614,1785,1810,1069,508,128,39]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbs79f94kkHR",
        "colab_type": "code",
        "outputId": "6e18eca8-ffa9-4ac4-9425-3b8de0a8ad9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "print(' Accident Years',accident_years)\n",
        "print(' Developement Years',development_years)\n",
        "print(' Input', triangle)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accident Years [2005 2006 2007 2008 2009 2010 2011 2012]\n",
            " Developement Years [0 1 2 3 4 5 6 7]\n",
            " Input [[1232  946  520  722  316  165   48   14]\n",
            " [1469 1201  708  845  461  235   56   18]\n",
            " [1652 1416  959  954  605  287   69   21]\n",
            " [1831 1634 1124 1087  725  314   79   24]\n",
            " [2074 1919 1330 1240  756  359   91   28]\n",
            " [2434 2263 1661 1540  909  432  109   33]\n",
            " [2810 2108 1544 1565  924  439  111   34]\n",
            " [3072 2614 1785 1810 1069  508  128   39]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5IuQnkDGDVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newTriangle= np.zeros([8,8])\n",
        "for i in range(triangle.shape[0]):\n",
        "  for j in range(triangle.shape[1]-i):\n",
        "    newTriangle[i,j]= triangle[i,j]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srjb5tnPGleb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "78358e73-ba39-40ae-d485-ae061c99659f"
      },
      "source": [
        "print(newTriangle)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1232.  946.  520.  722.  316.  165.   48.   14.]\n",
            " [1469. 1201.  708.  845.  461.  235.   56.    0.]\n",
            " [1652. 1416.  959.  954.  605.  287.    0.    0.]\n",
            " [1831. 1634. 1124. 1087.  725.    0.    0.    0.]\n",
            " [2074. 1919. 1330. 1240.    0.    0.    0.    0.]\n",
            " [2434. 2263. 1661.    0.    0.    0.    0.    0.]\n",
            " [2810. 2108.    0.    0.    0.    0.    0.    0.]\n",
            " [3072.    0.    0.    0.    0.    0.    0.    0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV9CyhyHkreC",
        "colab_type": "code",
        "outputId": "b75c3ed6-6533-4428-b2ea-b582148049e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Cum calc\n",
        "C = np.zeros(shape=(np.shape(triangle)[0],np.shape(triangle)[1]))\n",
        "for i in range(np.shape(triangle)[0]):\n",
        "    for j in range(np.shape(triangle)[1]):\n",
        "        C[i,j] = sum(triangle[i,:j+1])\n",
        "\n",
        "print('C',C)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C [[ 1232.  2178.  2698.  3420.  3736.  3901.  3949.  3963.]\n",
            " [ 1469.  2670.  3378.  4223.  4684.  4919.  4975.  4993.]\n",
            " [ 1652.  3068.  4027.  4981.  5586.  5873.  5942.  5963.]\n",
            " [ 1831.  3465.  4589.  5676.  6401.  6715.  6794.  6818.]\n",
            " [ 2074.  3993.  5323.  6563.  7319.  7678.  7769.  7797.]\n",
            " [ 2434.  4697.  6358.  7898.  8807.  9239.  9348.  9381.]\n",
            " [ 2810.  4918.  6462.  8027.  8951.  9390.  9501.  9535.]\n",
            " [ 3072.  5686.  7471.  9281. 10350. 10858. 10986. 11025.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioSsHmm7kvOY",
        "colab_type": "code",
        "outputId": "a1b5fe60-e023-43cd-aaf7-54e3cce0aa67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "l_encode = LabelEncoder()\n",
        "l_encode.fit(accident_years)\n",
        "a_yr = l_encode.transform(accident_years)\n",
        "l_encode.fit(development_years)\n",
        "dev_yr = l_encode.transform(development_years)\n",
        "\n",
        "print(a_yr)\n",
        "print(dev_yr)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7]\n",
            "[0 1 2 3 4 5 6 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyery7QfkzKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = []\n",
        "for i in range(np.shape(triangle)[0]):\n",
        "    for j in range(np.shape(triangle)[1]-i):\n",
        "        train_data.append([a_yr[i],dev_yr[j],C[i,j]])\n",
        "        \n",
        "test_data = []\n",
        "for i in range(1,np.shape(triangle)[0]):\n",
        "    for j in range(np.shape(triangle)[1]-i,np.shape(triangle)[1]):\n",
        "        test_data.append([a_yr[i],dev_yr[j],C[i,j]])\n",
        "\n",
        " \n",
        "#convert trainData and testData into numpyArray\n",
        "#train_data = np.array(train_data)\n",
        "test_data = np.array(test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95UOy6VzAcfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code for generating the other triangle\n",
        "\n",
        "for iteratrion in range(100):\n",
        "  newTriangle2= np.zeros((triangle.shape[0],triangle.shape[1]))\n",
        "  for i in range(triangle.shape[0]):\n",
        "    for j in range(triangle.shape[1]-i):\n",
        "        newTriangle2[i,j]= newTriangle[i,j] + np.random.randint(-10,10)\n",
        "  difference= newTriangle2-newTriangle\n",
        "  \n",
        "  #print(\"New Triangle:\\n\",newTriangle)\n",
        "  #print(\"New Triangle2:\\n\",newTriangle2)\n",
        "  #print(\"difference:\\n\",difference)\n",
        "  \n",
        "  \n",
        "  #get the column of the difference\n",
        "  columncount=triangle.shape[1]\n",
        "  for columnIndex in range(triangle.shape[1]):\n",
        "    column= difference[:columncount,columnIndex]\n",
        "    np.random.shuffle(column)\n",
        "    newTriangle[:columncount,columnIndex]= newTriangle[:columncount,columnIndex]+ column\n",
        "    columncount= columncount-1\n",
        "    \n",
        "  #print(\"Bootstrap New Triangle:\\n\")\n",
        "  #print(newTriangle)\n",
        "  \n",
        "  #find the cumulative sum of new Bootstrap New Triangle\n",
        "  # Cum calc\n",
        "  newC = np.zeros(shape=(np.shape(triangle)[0],np.shape(triangle)[1]))\n",
        "  for i in range(np.shape(triangle)[0]):\n",
        "    for j in range(np.shape(newTriangle)[1]):\n",
        "        newC[i,j] = sum(newTriangle[i,:j+1])\n",
        "\n",
        "  \n",
        "  \n",
        "  #combine the new triangle with the already existing training set\n",
        "  \n",
        "  for i in range(np.shape(triangle)[0]):\n",
        "    for j in range(np.shape(triangle)[1]-i):\n",
        "        train_data.append([a_yr[i],dev_yr[j],newC[i,j]])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8GNst3Lzl_C",
        "colab_type": "code",
        "outputId": "eaf15e8c-c151-47d1-b281-d9c757ee792e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_data= np.array(train_data)\n",
        "train_data.shape\n",
        "#train_data[71,:]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3636, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaQ869k1vjuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############\n",
        "# define the loss function\n",
        "################\n",
        "\n",
        "def poisson_dev(y_true, y_pred):\n",
        "    return 2*K.mean(y_pred - y_true -y_true*(K.log(K.clip(y_pred,K.epsilon(),None)) -K.log(K.clip(y_true,K.epsilon(),None))),axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-E5C-Oek8sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################\n",
        "# Step 3 : Build Model using Neural Networks\n",
        "# Note : MSE loss used here\n",
        "###############################\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras import regularizers\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from keras.callbacks import RemoteMonitor\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras import optimizers\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBoVSoy4m0pk",
        "colab_type": "code",
        "outputId": "fd90962d-b9f5-449b-c4f5-d253c7822aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10559
        }
      },
      "source": [
        "###################\n",
        "# Auto Encoder Network Architecture #\n",
        "######################\n",
        "\n",
        "#encoder part\n",
        "inputData= Input(shape=(2,))\n",
        "encoded= Dense(20,activation='relu',kernel_initializer='normal')(inputData)\n",
        "encoded= Dense(10,activation='relu')(encoded)\n",
        "encoded= Dense(2,activation='relu')(encoded)  #latent space representation\n",
        "\n",
        "#decoder part\n",
        "decoded = Dense(10, activation='relu')(encoded)\n",
        "decoded = Dense(20, activation='relu')(decoded)\n",
        "decoded = Dense(2, activation='relu')(decoded)\n",
        "\n",
        "#combine the encoder and the decoder\n",
        "autoencoder = Model(inputData, decoded)\n",
        "\n",
        "#get only the encoder part\n",
        "encoderPart= Model(inputData,encoded)\n",
        "\n",
        "adam = optimizers.Adam(lr=0.1)\n",
        "autoencoder.compile(loss=\"mse\", optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=0)\n",
        "filepath=\"v5.best.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True)\n",
        "\n",
        "#history = autoencoder.fit(x=train_data[:,:2], y=train_data[:,:2], batch_size=1, epochs=300, verbose=1, callbacks=[checkpointer,reduce_lr,early_stop], validation_split=0.3, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
        "history = autoencoder.fit(x=train_data[:,:2], y=train_data[:,:2], batch_size=1, epochs=300, verbose=1, callbacks=None, validation_split=0.3, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 2545 samples, validate on 1091 samples\n",
            "Epoch 1/300\n",
            "2545/2545 [==============================] - 4s 1ms/step - loss: 0.7511 - acc: 0.8943 - val_loss: 5.5465e-05 - val_acc: 0.9175\n",
            "Epoch 2/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0018 - acc: 0.9446 - val_loss: 7.8132e-06 - val_acc: 0.9450\n",
            "Epoch 3/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0019 - acc: 0.9521 - val_loss: 2.5581e-04 - val_acc: 1.0000\n",
            "Epoch 4/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0034 - acc: 0.9682 - val_loss: 8.4500e-04 - val_acc: 1.0000\n",
            "Epoch 5/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0030 - acc: 0.9580 - val_loss: 9.1562e-06 - val_acc: 0.9450\n",
            "Epoch 6/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0041 - acc: 0.9595 - val_loss: 2.1874e-05 - val_acc: 1.0000\n",
            "Epoch 7/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9627 - val_loss: 2.0880e-05 - val_acc: 1.0000\n",
            "Epoch 8/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0016 - acc: 0.9595 - val_loss: 1.8954e-05 - val_acc: 0.9725\n",
            "Epoch 9/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9540 - val_loss: 0.0018 - val_acc: 0.9175\n",
            "Epoch 10/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0022 - acc: 0.9591 - val_loss: 0.0122 - val_acc: 1.0000\n",
            "Epoch 11/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0022 - acc: 0.9568 - val_loss: 2.1720e-04 - val_acc: 0.9175\n",
            "Epoch 12/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0019 - acc: 0.9599 - val_loss: 5.3752e-05 - val_acc: 1.0000\n",
            "Epoch 13/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0021 - acc: 0.9536 - val_loss: 0.0021 - val_acc: 1.0000\n",
            "Epoch 14/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0023 - acc: 0.9513 - val_loss: 7.2080e-04 - val_acc: 0.9175\n",
            "Epoch 15/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9572 - val_loss: 9.0702e-05 - val_acc: 0.9450\n",
            "Epoch 16/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0022 - acc: 0.9572 - val_loss: 1.2269e-05 - val_acc: 1.0000\n",
            "Epoch 17/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0023 - acc: 0.9611 - val_loss: 0.0048 - val_acc: 0.9175\n",
            "Epoch 18/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0015 - acc: 0.9591 - val_loss: 2.1807e-05 - val_acc: 1.0000\n",
            "Epoch 19/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0016 - acc: 0.9654 - val_loss: 3.7947e-06 - val_acc: 0.9450\n",
            "Epoch 20/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0020 - acc: 0.9544 - val_loss: 5.2744e-04 - val_acc: 0.9175\n",
            "Epoch 21/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0017 - acc: 0.9572 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 22/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0017 - acc: 0.9568 - val_loss: 8.7504e-06 - val_acc: 1.0000\n",
            "Epoch 23/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0013 - acc: 0.9623 - val_loss: 4.1593e-05 - val_acc: 0.9725\n",
            "Epoch 24/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 1.0000\n",
            "Epoch 25/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0015 - acc: 0.9611 - val_loss: 5.8802e-05 - val_acc: 0.9175\n",
            "Epoch 26/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0010 - acc: 0.9650 - val_loss: 4.6543e-04 - val_acc: 0.9175\n",
            "Epoch 27/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0024 - acc: 0.9650 - val_loss: 4.0159e-05 - val_acc: 1.0000\n",
            "Epoch 28/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.3709e-04 - acc: 0.9650 - val_loss: 7.5387e-05 - val_acc: 1.0000\n",
            "Epoch 29/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0035 - acc: 0.9580 - val_loss: 1.4631e-04 - val_acc: 0.9175\n",
            "Epoch 30/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.9913e-04 - acc: 0.9666 - val_loss: 1.4601e-04 - val_acc: 1.0000\n",
            "Epoch 31/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0016 - acc: 0.9603 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 32/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0015 - acc: 0.9607 - val_loss: 1.7524e-04 - val_acc: 1.0000\n",
            "Epoch 33/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0028 - acc: 0.9603 - val_loss: 2.1864e-05 - val_acc: 0.9725\n",
            "Epoch 34/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0010 - acc: 0.9635 - val_loss: 1.3995e-04 - val_acc: 0.9175\n",
            "Epoch 35/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0029 - acc: 0.9690 - val_loss: 1.0112e-06 - val_acc: 1.0000\n",
            "Epoch 36/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0023 - acc: 0.9572 - val_loss: 8.5922e-06 - val_acc: 1.0000\n",
            "Epoch 37/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.4154e-04 - acc: 0.9611 - val_loss: 1.1074e-04 - val_acc: 1.0000\n",
            "Epoch 38/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0013 - acc: 0.9544 - val_loss: 2.7378e-04 - val_acc: 0.9175\n",
            "Epoch 39/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0014 - acc: 0.9587 - val_loss: 0.0055 - val_acc: 0.9725\n",
            "Epoch 40/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9580 - val_loss: 2.9757e-04 - val_acc: 0.9175\n",
            "Epoch 41/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0015 - acc: 0.9544 - val_loss: 0.0019 - val_acc: 0.9175\n",
            "Epoch 42/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0013 - acc: 0.9544 - val_loss: 7.5624e-06 - val_acc: 0.9175\n",
            "Epoch 43/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9583 - val_loss: 0.0044 - val_acc: 0.9175\n",
            "Epoch 44/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9450 - val_loss: 9.9472e-05 - val_acc: 1.0000\n",
            "Epoch 45/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0021 - acc: 0.9587 - val_loss: 0.0012 - val_acc: 0.9175\n",
            "Epoch 46/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0013 - acc: 0.9544 - val_loss: 3.7469e-06 - val_acc: 0.9175\n",
            "Epoch 47/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0013 - acc: 0.9513 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 48/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0015 - acc: 0.9572 - val_loss: 0.0059 - val_acc: 1.0000\n",
            "Epoch 49/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9595 - val_loss: 3.8299e-05 - val_acc: 1.0000\n",
            "Epoch 50/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0010 - acc: 0.9536 - val_loss: 1.2817e-04 - val_acc: 0.9450\n",
            "Epoch 51/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9595 - val_loss: 5.1323e-05 - val_acc: 0.9175\n",
            "Epoch 52/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0017 - acc: 0.9552 - val_loss: 2.5758e-04 - val_acc: 0.9175\n",
            "Epoch 53/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.7710e-04 - acc: 0.9525 - val_loss: 0.0069 - val_acc: 0.9175\n",
            "Epoch 54/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9603 - val_loss: 9.1924e-05 - val_acc: 0.9175\n",
            "Epoch 55/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9603 - val_loss: 1.7074e-04 - val_acc: 0.9450\n",
            "Epoch 56/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9603 - val_loss: 6.2941e-04 - val_acc: 1.0000\n",
            "Epoch 57/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0024 - acc: 0.9580 - val_loss: 7.4882e-06 - val_acc: 0.9175\n",
            "Epoch 58/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9576 - val_loss: 1.1430e-04 - val_acc: 0.9175\n",
            "Epoch 59/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9576 - val_loss: 2.8494e-04 - val_acc: 1.0000\n",
            "Epoch 60/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9481 - val_loss: 0.0295 - val_acc: 1.0000\n",
            "Epoch 61/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0018 - acc: 0.9544 - val_loss: 4.6192e-04 - val_acc: 1.0000\n",
            "Epoch 62/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0021 - acc: 0.9599 - val_loss: 4.1935e-05 - val_acc: 0.9175\n",
            "Epoch 63/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.3368e-04 - acc: 0.9540 - val_loss: 6.5244e-05 - val_acc: 0.9175\n",
            "Epoch 64/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9591 - val_loss: 8.6046e-06 - val_acc: 1.0000\n",
            "Epoch 65/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9477 - val_loss: 0.0083 - val_acc: 0.9175\n",
            "Epoch 66/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0017 - acc: 0.9560 - val_loss: 3.1825e-05 - val_acc: 0.9725\n",
            "Epoch 67/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0017 - acc: 0.9528 - val_loss: 6.4729e-05 - val_acc: 0.9175\n",
            "Epoch 68/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.0260e-04 - acc: 0.9536 - val_loss: 2.2955e-05 - val_acc: 0.9725\n",
            "Epoch 69/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0022 - acc: 0.9411 - val_loss: 2.2871e-05 - val_acc: 0.9450\n",
            "Epoch 70/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0018 - acc: 0.9501 - val_loss: 8.0334e-06 - val_acc: 0.9175\n",
            "Epoch 71/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.4178e-04 - acc: 0.9556 - val_loss: 4.9012e-05 - val_acc: 1.0000\n",
            "Epoch 72/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.9417e-04 - acc: 0.9497 - val_loss: 1.4786e-05 - val_acc: 0.9450\n",
            "Epoch 73/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0026 - acc: 0.9564 - val_loss: 1.0486e-04 - val_acc: 0.9175\n",
            "Epoch 74/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.1025e-04 - acc: 0.9564 - val_loss: 4.5520e-06 - val_acc: 0.9450\n",
            "Epoch 75/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0020 - acc: 0.9544 - val_loss: 7.9724e-05 - val_acc: 0.9175\n",
            "Epoch 76/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.4550e-04 - acc: 0.9635 - val_loss: 1.2103e-05 - val_acc: 1.0000\n",
            "Epoch 77/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.2561e-04 - acc: 0.9603 - val_loss: 7.8343e-05 - val_acc: 1.0000\n",
            "Epoch 78/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0018 - acc: 0.9619 - val_loss: 6.8935e-05 - val_acc: 1.0000\n",
            "Epoch 79/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.8431e-04 - acc: 0.9568 - val_loss: 4.7324e-05 - val_acc: 0.9175\n",
            "Epoch 80/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.3515e-04 - acc: 0.9564 - val_loss: 9.4536e-06 - val_acc: 0.9175\n",
            "Epoch 81/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.5306e-04 - acc: 0.9615 - val_loss: 8.2377e-04 - val_acc: 0.9725\n",
            "Epoch 82/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9576 - val_loss: 7.0370e-04 - val_acc: 0.9175\n",
            "Epoch 83/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.5983e-04 - acc: 0.9583 - val_loss: 6.4746e-04 - val_acc: 1.0000\n",
            "Epoch 84/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0014 - acc: 0.9536 - val_loss: 1.0824e-05 - val_acc: 0.9175\n",
            "Epoch 85/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9627 - val_loss: 8.0782e-06 - val_acc: 0.9725\n",
            "Epoch 86/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.0981e-04 - acc: 0.9662 - val_loss: 5.9787e-04 - val_acc: 0.9175\n",
            "Epoch 87/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.8056e-04 - acc: 0.9536 - val_loss: 8.6371e-04 - val_acc: 0.9175\n",
            "Epoch 88/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0021 - acc: 0.9611 - val_loss: 0.0083 - val_acc: 0.9175\n",
            "Epoch 89/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 2.3927e-04 - acc: 0.9528 - val_loss: 0.0020 - val_acc: 0.9175\n",
            "Epoch 90/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.7837e-04 - acc: 0.9595 - val_loss: 0.0020 - val_acc: 0.9450\n",
            "Epoch 91/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.3476e-04 - acc: 0.9619 - val_loss: 6.1509e-04 - val_acc: 0.9175\n",
            "Epoch 92/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0010 - acc: 0.9646 - val_loss: 1.5329e-04 - val_acc: 1.0000\n",
            "Epoch 93/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.6920e-04 - acc: 0.9603 - val_loss: 4.1487e-05 - val_acc: 1.0000\n",
            "Epoch 94/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.4053e-04 - acc: 0.9568 - val_loss: 7.1192e-04 - val_acc: 0.9175\n",
            "Epoch 95/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.8572e-04 - acc: 0.9564 - val_loss: 3.7822e-04 - val_acc: 0.9175\n",
            "Epoch 96/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0020 - acc: 0.9674 - val_loss: 4.4941e-06 - val_acc: 1.0000\n",
            "Epoch 97/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.3999e-04 - acc: 0.9580 - val_loss: 1.3380e-05 - val_acc: 0.9725\n",
            "Epoch 98/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.5899e-04 - acc: 0.9580 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 99/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9642 - val_loss: 4.0588e-05 - val_acc: 1.0000\n",
            "Epoch 100/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0010 - acc: 0.9674 - val_loss: 6.3153e-05 - val_acc: 1.0000\n",
            "Epoch 101/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.8731e-04 - acc: 0.9611 - val_loss: 6.4143e-05 - val_acc: 1.0000\n",
            "Epoch 102/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.9190e-04 - acc: 0.9709 - val_loss: 3.3632e-05 - val_acc: 1.0000\n",
            "Epoch 103/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0017 - acc: 0.9666 - val_loss: 5.3550e-04 - val_acc: 0.9450\n",
            "Epoch 104/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0023 - acc: 0.9760 - val_loss: 3.1328e-05 - val_acc: 0.9725\n",
            "Epoch 105/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.5884e-04 - acc: 0.9756 - val_loss: 4.2327e-05 - val_acc: 0.9450\n",
            "Epoch 106/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9607 - val_loss: 1.9088e-04 - val_acc: 0.9450\n",
            "Epoch 107/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0019 - acc: 0.9619 - val_loss: 7.7444e-05 - val_acc: 0.9725\n",
            "Epoch 108/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.0661e-04 - acc: 0.9595 - val_loss: 0.0062 - val_acc: 1.0000\n",
            "Epoch 109/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.8687e-04 - acc: 0.9572 - val_loss: 5.0636e-04 - val_acc: 0.9725\n",
            "Epoch 110/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.7671e-04 - acc: 0.9642 - val_loss: 5.2051e-04 - val_acc: 1.0000\n",
            "Epoch 111/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.0559e-04 - acc: 0.9587 - val_loss: 3.3704e-05 - val_acc: 1.0000\n",
            "Epoch 112/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.8972e-04 - acc: 0.9583 - val_loss: 4.2128e-05 - val_acc: 1.0000\n",
            "Epoch 113/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.3496e-04 - acc: 0.9607 - val_loss: 4.2178e-04 - val_acc: 0.9725\n",
            "Epoch 114/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9642 - val_loss: 8.9926e-06 - val_acc: 0.9450\n",
            "Epoch 115/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.1098e-04 - acc: 0.9646 - val_loss: 7.9195e-06 - val_acc: 0.9450\n",
            "Epoch 116/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.6219e-04 - acc: 0.9580 - val_loss: 9.5009e-06 - val_acc: 0.9725\n",
            "Epoch 117/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.7660e-04 - acc: 0.9639 - val_loss: 1.9521e-05 - val_acc: 0.9175\n",
            "Epoch 118/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.5861e-04 - acc: 0.9627 - val_loss: 6.4835e-04 - val_acc: 0.9175\n",
            "Epoch 119/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9635 - val_loss: 1.0035e-04 - val_acc: 1.0000\n",
            "Epoch 120/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.8315e-04 - acc: 0.9611 - val_loss: 0.0099 - val_acc: 1.0000\n",
            "Epoch 121/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0017 - acc: 0.9674 - val_loss: 2.1791e-04 - val_acc: 1.0000\n",
            "Epoch 122/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 1.9746e-04 - acc: 0.9674 - val_loss: 5.1504e-04 - val_acc: 0.9175\n",
            "Epoch 123/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0020 - acc: 0.9615 - val_loss: 7.3167e-05 - val_acc: 0.9175\n",
            "Epoch 124/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 2.3782e-04 - acc: 0.9705 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "Epoch 125/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9717 - val_loss: 2.3516e-05 - val_acc: 1.0000\n",
            "Epoch 126/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.5760e-04 - acc: 0.9603 - val_loss: 1.7039e-05 - val_acc: 0.9725\n",
            "Epoch 127/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.4251e-04 - acc: 0.9635 - val_loss: 0.0119 - val_acc: 0.9175\n",
            "Epoch 128/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.7617e-04 - acc: 0.9666 - val_loss: 1.3190e-05 - val_acc: 1.0000\n",
            "Epoch 129/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0017 - acc: 0.9658 - val_loss: 0.0019 - val_acc: 0.9175\n",
            "Epoch 130/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.1385e-04 - acc: 0.9631 - val_loss: 0.0022 - val_acc: 1.0000\n",
            "Epoch 131/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 3.9787e-04 - acc: 0.9686 - val_loss: 3.5025e-04 - val_acc: 0.9450\n",
            "Epoch 132/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.8005e-04 - acc: 0.9599 - val_loss: 5.6884e-05 - val_acc: 0.9450\n",
            "Epoch 133/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9599 - val_loss: 2.0143e-05 - val_acc: 1.0000\n",
            "Epoch 134/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.6242e-04 - acc: 0.9623 - val_loss: 2.6222e-05 - val_acc: 1.0000\n",
            "Epoch 135/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.5553e-04 - acc: 0.9666 - val_loss: 3.2126e-05 - val_acc: 1.0000\n",
            "Epoch 136/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0017 - acc: 0.9611 - val_loss: 2.6331e-05 - val_acc: 0.9450\n",
            "Epoch 137/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 2.3799e-04 - acc: 0.9690 - val_loss: 4.4083e-04 - val_acc: 0.9175\n",
            "Epoch 138/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.6180e-04 - acc: 0.9576 - val_loss: 2.7663e-05 - val_acc: 0.9450\n",
            "Epoch 139/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.0156e-04 - acc: 0.9568 - val_loss: 1.8086e-04 - val_acc: 0.9725\n",
            "Epoch 140/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0014 - acc: 0.9540 - val_loss: 2.6512e-04 - val_acc: 1.0000\n",
            "Epoch 141/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.6590e-04 - acc: 0.9725 - val_loss: 3.4857e-06 - val_acc: 0.9725\n",
            "Epoch 142/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.5861e-04 - acc: 0.9690 - val_loss: 7.1461e-06 - val_acc: 1.0000\n",
            "Epoch 143/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.6660e-04 - acc: 0.9654 - val_loss: 3.1682e-05 - val_acc: 1.0000\n",
            "Epoch 144/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.0708e-04 - acc: 0.9615 - val_loss: 2.2694e-04 - val_acc: 0.9175\n",
            "Epoch 145/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.4899e-04 - acc: 0.9627 - val_loss: 1.5043e-05 - val_acc: 0.9725\n",
            "Epoch 146/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.7459e-04 - acc: 0.9654 - val_loss: 3.5502e-04 - val_acc: 0.9450\n",
            "Epoch 147/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0010 - acc: 0.9654 - val_loss: 0.0042 - val_acc: 1.0000\n",
            "Epoch 148/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.8524e-04 - acc: 0.9619 - val_loss: 2.9766e-06 - val_acc: 0.9450\n",
            "Epoch 149/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.4753e-04 - acc: 0.9662 - val_loss: 2.4263e-05 - val_acc: 0.9725\n",
            "Epoch 150/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0014 - acc: 0.9690 - val_loss: 5.5247e-05 - val_acc: 0.9450\n",
            "Epoch 151/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 3.5941e-04 - acc: 0.9631 - val_loss: 1.8845e-04 - val_acc: 0.9175\n",
            "Epoch 152/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.4538e-04 - acc: 0.9635 - val_loss: 3.0859e-06 - val_acc: 0.9450\n",
            "Epoch 153/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.3069e-04 - acc: 0.9642 - val_loss: 4.3248e-06 - val_acc: 1.0000\n",
            "Epoch 154/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.5640e-04 - acc: 0.9599 - val_loss: 3.2169e-05 - val_acc: 1.0000\n",
            "Epoch 155/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9544 - val_loss: 1.1049e-05 - val_acc: 0.9175\n",
            "Epoch 156/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.9562e-04 - acc: 0.9631 - val_loss: 5.6665e-04 - val_acc: 1.0000\n",
            "Epoch 157/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 3.5763e-04 - acc: 0.9658 - val_loss: 5.0527e-06 - val_acc: 0.9725\n",
            "Epoch 158/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.0919e-04 - acc: 0.9635 - val_loss: 1.3560e-05 - val_acc: 1.0000\n",
            "Epoch 159/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.9416e-04 - acc: 0.9650 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 160/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.4416e-04 - acc: 0.9627 - val_loss: 2.6676e-05 - val_acc: 1.0000\n",
            "Epoch 161/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.2130e-04 - acc: 0.9619 - val_loss: 1.2168e-05 - val_acc: 1.0000\n",
            "Epoch 162/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.1540e-04 - acc: 0.9540 - val_loss: 0.0014 - val_acc: 0.9175\n",
            "Epoch 163/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.2573e-04 - acc: 0.9583 - val_loss: 2.2836e-05 - val_acc: 0.9450\n",
            "Epoch 164/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.8685e-04 - acc: 0.9576 - val_loss: 2.0962e-04 - val_acc: 0.9175\n",
            "Epoch 165/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9595 - val_loss: 9.8892e-06 - val_acc: 0.9450\n",
            "Epoch 166/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.4582e-04 - acc: 0.9729 - val_loss: 3.6951e-04 - val_acc: 1.0000\n",
            "Epoch 167/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0017 - acc: 0.9717 - val_loss: 9.2120e-06 - val_acc: 1.0000\n",
            "Epoch 168/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 3.9515e-04 - acc: 0.9595 - val_loss: 0.0055 - val_acc: 1.0000\n",
            "Epoch 169/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.4614e-04 - acc: 0.9619 - val_loss: 6.6550e-04 - val_acc: 0.9450\n",
            "Epoch 170/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.9455e-04 - acc: 0.9564 - val_loss: 1.2327e-05 - val_acc: 0.9450\n",
            "Epoch 171/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0015 - acc: 0.9674 - val_loss: 2.5909e-06 - val_acc: 0.9450\n",
            "Epoch 172/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.6328e-04 - acc: 0.9580 - val_loss: 8.6985e-04 - val_acc: 1.0000\n",
            "Epoch 173/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.4712e-04 - acc: 0.9568 - val_loss: 2.2071e-04 - val_acc: 0.9175\n",
            "Epoch 174/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.6484e-04 - acc: 0.9674 - val_loss: 6.1828e-05 - val_acc: 0.9175\n",
            "Epoch 175/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.8333e-04 - acc: 0.9509 - val_loss: 5.4206e-06 - val_acc: 0.9450\n",
            "Epoch 176/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9489 - val_loss: 4.3459e-05 - val_acc: 1.0000\n",
            "Epoch 177/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0012 - acc: 0.9635 - val_loss: 1.1424e-05 - val_acc: 1.0000\n",
            "Epoch 178/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.4159e-04 - acc: 0.9611 - val_loss: 3.4934e-04 - val_acc: 1.0000\n",
            "Epoch 179/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.2605e-04 - acc: 0.9536 - val_loss: 5.4931e-05 - val_acc: 0.9175\n",
            "Epoch 180/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.6736e-04 - acc: 0.9572 - val_loss: 0.0036 - val_acc: 0.9725\n",
            "Epoch 181/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0013 - acc: 0.9587 - val_loss: 3.5330e-05 - val_acc: 1.0000\n",
            "Epoch 182/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.2242e-04 - acc: 0.9611 - val_loss: 8.8148e-04 - val_acc: 0.9175\n",
            "Epoch 183/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.3044e-04 - acc: 0.9607 - val_loss: 2.2119e-06 - val_acc: 0.9725\n",
            "Epoch 184/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.2521e-04 - acc: 0.9587 - val_loss: 8.1290e-05 - val_acc: 1.0000\n",
            "Epoch 185/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0016 - acc: 0.9611 - val_loss: 4.0586e-05 - val_acc: 1.0000\n",
            "Epoch 186/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.1551e-04 - acc: 0.9501 - val_loss: 6.9290e-06 - val_acc: 0.9725\n",
            "Epoch 187/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.3345e-04 - acc: 0.9564 - val_loss: 1.0889e-04 - val_acc: 0.9175\n",
            "Epoch 188/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.5332e-04 - acc: 0.9525 - val_loss: 4.3414e-05 - val_acc: 1.0000\n",
            "Epoch 189/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.9301e-04 - acc: 0.9568 - val_loss: 1.8773e-05 - val_acc: 0.9175\n",
            "Epoch 190/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9470 - val_loss: 2.0502e-06 - val_acc: 0.9725\n",
            "Epoch 191/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.4517e-04 - acc: 0.9481 - val_loss: 4.5386e-06 - val_acc: 0.9175\n",
            "Epoch 192/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.9104e-04 - acc: 0.9591 - val_loss: 1.5322e-06 - val_acc: 0.9725\n",
            "Epoch 193/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.4822e-04 - acc: 0.9599 - val_loss: 1.0521e-04 - val_acc: 0.9450\n",
            "Epoch 194/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.3645e-04 - acc: 0.9525 - val_loss: 8.3942e-06 - val_acc: 0.9175\n",
            "Epoch 195/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.8074e-04 - acc: 0.9568 - val_loss: 1.3533e-05 - val_acc: 0.9725\n",
            "Epoch 196/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.8332e-04 - acc: 0.9615 - val_loss: 2.6622e-04 - val_acc: 0.9450\n",
            "Epoch 197/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.1609e-04 - acc: 0.9611 - val_loss: 6.2986e-05 - val_acc: 0.9175\n",
            "Epoch 198/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.9969e-04 - acc: 0.9591 - val_loss: 6.5547e-06 - val_acc: 0.9450\n",
            "Epoch 199/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.6776e-04 - acc: 0.9599 - val_loss: 1.0503e-05 - val_acc: 0.9725\n",
            "Epoch 200/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.9122e-04 - acc: 0.9635 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 201/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.9278e-04 - acc: 0.9639 - val_loss: 0.0021 - val_acc: 0.9175\n",
            "Epoch 202/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.3541e-04 - acc: 0.9591 - val_loss: 6.8681e-04 - val_acc: 0.9450\n",
            "Epoch 203/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0010 - acc: 0.9607 - val_loss: 4.7508e-05 - val_acc: 1.0000\n",
            "Epoch 204/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.5770e-04 - acc: 0.9548 - val_loss: 9.3742e-05 - val_acc: 0.9725\n",
            "Epoch 205/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.9752e-04 - acc: 0.9540 - val_loss: 2.1323e-05 - val_acc: 0.9725\n",
            "Epoch 206/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.8600e-04 - acc: 0.9521 - val_loss: 8.0422e-06 - val_acc: 0.9175\n",
            "Epoch 207/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.8718e-04 - acc: 0.9497 - val_loss: 6.3021e-05 - val_acc: 0.9450\n",
            "Epoch 208/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.5780e-04 - acc: 0.9501 - val_loss: 5.6370e-06 - val_acc: 0.9175\n",
            "Epoch 209/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.5858e-04 - acc: 0.9591 - val_loss: 1.3075e-04 - val_acc: 0.9725\n",
            "Epoch 210/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.0474e-04 - acc: 0.9587 - val_loss: 1.0441e-05 - val_acc: 1.0000\n",
            "Epoch 211/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.9771e-04 - acc: 0.9623 - val_loss: 6.2947e-05 - val_acc: 1.0000\n",
            "Epoch 212/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.1430e-04 - acc: 0.9583 - val_loss: 1.7152e-06 - val_acc: 0.9175\n",
            "Epoch 213/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.0049e-04 - acc: 0.9497 - val_loss: 1.2655e-04 - val_acc: 0.9725\n",
            "Epoch 214/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.0332e-04 - acc: 0.9497 - val_loss: 6.2804e-04 - val_acc: 1.0000\n",
            "Epoch 215/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.6614e-04 - acc: 0.9489 - val_loss: 2.0655e-06 - val_acc: 0.9450\n",
            "Epoch 216/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.0312e-04 - acc: 0.9552 - val_loss: 1.4039e-05 - val_acc: 0.9450\n",
            "Epoch 217/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 3.0731e-04 - acc: 0.9532 - val_loss: 1.5570e-04 - val_acc: 0.9175\n",
            "Epoch 218/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.3640e-04 - acc: 0.9489 - val_loss: 2.4161e-05 - val_acc: 0.9725\n",
            "Epoch 219/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0010 - acc: 0.9509 - val_loss: 5.4885e-06 - val_acc: 1.0000\n",
            "Epoch 220/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9556 - val_loss: 0.0013 - val_acc: 0.9725\n",
            "Epoch 221/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.8485e-04 - acc: 0.9513 - val_loss: 9.7554e-05 - val_acc: 0.9175\n",
            "Epoch 222/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.2354e-04 - acc: 0.9611 - val_loss: 8.0375e-05 - val_acc: 0.9175\n",
            "Epoch 223/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.4706e-04 - acc: 0.9536 - val_loss: 2.2646e-05 - val_acc: 1.0000\n",
            "Epoch 224/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.7034e-04 - acc: 0.9485 - val_loss: 3.7573e-06 - val_acc: 0.9175\n",
            "Epoch 225/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.5164e-04 - acc: 0.9635 - val_loss: 1.9001e-04 - val_acc: 1.0000\n",
            "Epoch 226/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.4748e-04 - acc: 0.9525 - val_loss: 1.0405e-05 - val_acc: 0.9725\n",
            "Epoch 227/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.8051e-04 - acc: 0.9552 - val_loss: 1.3769e-05 - val_acc: 1.0000\n",
            "Epoch 228/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.5938e-04 - acc: 0.9595 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 229/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.9195e-04 - acc: 0.9532 - val_loss: 2.3902e-05 - val_acc: 0.9175\n",
            "Epoch 230/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.6624e-04 - acc: 0.9489 - val_loss: 7.3844e-05 - val_acc: 0.9175\n",
            "Epoch 231/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.7205e-04 - acc: 0.9536 - val_loss: 1.3648e-05 - val_acc: 0.9175\n",
            "Epoch 232/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.0050e-04 - acc: 0.9481 - val_loss: 2.2045e-04 - val_acc: 0.9175\n",
            "Epoch 233/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.7658e-04 - acc: 0.9513 - val_loss: 5.5898e-06 - val_acc: 0.9725\n",
            "Epoch 234/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 0.9485 - val_loss: 1.4111e-05 - val_acc: 0.9175\n",
            "Epoch 235/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.2174e-04 - acc: 0.9556 - val_loss: 0.0059 - val_acc: 0.9175\n",
            "Epoch 236/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.7194e-04 - acc: 0.9509 - val_loss: 4.3350e-06 - val_acc: 0.9175\n",
            "Epoch 237/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0010 - acc: 0.9556 - val_loss: 1.6214e-04 - val_acc: 0.9175\n",
            "Epoch 238/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 2.1667e-04 - acc: 0.9513 - val_loss: 2.6077e-04 - val_acc: 0.9725\n",
            "Epoch 239/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.3866e-04 - acc: 0.9607 - val_loss: 1.1163e-04 - val_acc: 0.9175\n",
            "Epoch 240/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.4280e-04 - acc: 0.9658 - val_loss: 2.2176e-06 - val_acc: 0.9725\n",
            "Epoch 241/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.2827e-04 - acc: 0.9595 - val_loss: 9.4520e-05 - val_acc: 0.9175\n",
            "Epoch 242/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 3.9096e-04 - acc: 0.9525 - val_loss: 4.6469e-04 - val_acc: 0.9175\n",
            "Epoch 243/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.3687e-04 - acc: 0.9540 - val_loss: 2.0168e-05 - val_acc: 0.9725\n",
            "Epoch 244/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.9423e-04 - acc: 0.9603 - val_loss: 3.8536e-04 - val_acc: 1.0000\n",
            "Epoch 245/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.8676e-04 - acc: 0.9564 - val_loss: 9.3228e-06 - val_acc: 0.9725\n",
            "Epoch 246/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.4027e-04 - acc: 0.9576 - val_loss: 8.7806e-05 - val_acc: 1.0000\n",
            "Epoch 247/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.9164e-04 - acc: 0.9599 - val_loss: 0.0021 - val_acc: 1.0000\n",
            "Epoch 248/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.9367e-04 - acc: 0.9536 - val_loss: 1.1710e-05 - val_acc: 1.0000\n",
            "Epoch 249/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.3884e-04 - acc: 0.9580 - val_loss: 0.0058 - val_acc: 0.9175\n",
            "Epoch 250/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.8240e-04 - acc: 0.9521 - val_loss: 7.6156e-06 - val_acc: 0.9175\n",
            "Epoch 251/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.5982e-04 - acc: 0.9525 - val_loss: 5.7614e-06 - val_acc: 0.9450\n",
            "Epoch 252/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.7741e-04 - acc: 0.9564 - val_loss: 1.9683e-05 - val_acc: 0.9725\n",
            "Epoch 253/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 3.9780e-04 - acc: 0.9509 - val_loss: 2.9647e-04 - val_acc: 0.9175\n",
            "Epoch 254/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.7013e-04 - acc: 0.9556 - val_loss: 4.4298e-04 - val_acc: 1.0000\n",
            "Epoch 255/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.0640e-04 - acc: 0.9635 - val_loss: 3.2414e-04 - val_acc: 0.9175\n",
            "Epoch 256/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.1176e-04 - acc: 0.9682 - val_loss: 1.5479e-04 - val_acc: 1.0000\n",
            "Epoch 257/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.3938e-04 - acc: 0.9619 - val_loss: 4.1975e-05 - val_acc: 1.0000\n",
            "Epoch 258/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.1001e-04 - acc: 0.9540 - val_loss: 6.0260e-05 - val_acc: 0.9450\n",
            "Epoch 259/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 3.7584e-04 - acc: 0.9489 - val_loss: 0.0153 - val_acc: 1.0000\n",
            "Epoch 260/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.1419e-04 - acc: 0.9599 - val_loss: 1.5659e-04 - val_acc: 0.9725\n",
            "Epoch 261/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.5422e-04 - acc: 0.9591 - val_loss: 1.9132e-05 - val_acc: 0.9450\n",
            "Epoch 262/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.7729e-04 - acc: 0.9485 - val_loss: 1.1486e-05 - val_acc: 0.9175\n",
            "Epoch 263/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.1382e-04 - acc: 0.9583 - val_loss: 5.8660e-05 - val_acc: 0.9175\n",
            "Epoch 264/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.2857e-04 - acc: 0.9615 - val_loss: 1.7681e-06 - val_acc: 0.9450\n",
            "Epoch 265/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.6020e-04 - acc: 0.9595 - val_loss: 0.0028 - val_acc: 1.0000\n",
            "Epoch 266/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.8032e-04 - acc: 0.9607 - val_loss: 4.3246e-04 - val_acc: 0.9450\n",
            "Epoch 267/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.0592e-04 - acc: 0.9576 - val_loss: 6.3301e-04 - val_acc: 0.9175\n",
            "Epoch 268/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0016 - acc: 0.9532 - val_loss: 1.6884e-04 - val_acc: 0.9175\n",
            "Epoch 269/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 2.7526e-04 - acc: 0.9509 - val_loss: 4.0723e-04 - val_acc: 1.0000\n",
            "Epoch 270/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.4362e-04 - acc: 0.9430 - val_loss: 5.3921e-06 - val_acc: 0.9175\n",
            "Epoch 271/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.4058e-04 - acc: 0.9650 - val_loss: 1.2344e-05 - val_acc: 1.0000\n",
            "Epoch 272/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.7568e-04 - acc: 0.9548 - val_loss: 1.3426e-05 - val_acc: 0.9175\n",
            "Epoch 273/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.3499e-04 - acc: 0.9623 - val_loss: 0.0071 - val_acc: 0.9175\n",
            "Epoch 274/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.7086e-04 - acc: 0.9556 - val_loss: 7.3006e-06 - val_acc: 1.0000\n",
            "Epoch 275/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.5701e-04 - acc: 0.9611 - val_loss: 0.0054 - val_acc: 0.9175\n",
            "Epoch 276/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.9160e-04 - acc: 0.9540 - val_loss: 2.8988e-05 - val_acc: 0.9175\n",
            "Epoch 277/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.7119e-04 - acc: 0.9642 - val_loss: 4.5531e-04 - val_acc: 1.0000\n",
            "Epoch 278/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.6190e-04 - acc: 0.9780 - val_loss: 2.8357e-04 - val_acc: 0.9175\n",
            "Epoch 279/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.3102e-04 - acc: 0.9462 - val_loss: 1.3955e-04 - val_acc: 0.9725\n",
            "Epoch 280/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.7138e-04 - acc: 0.9560 - val_loss: 7.4914e-04 - val_acc: 0.9175\n",
            "Epoch 281/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.3996e-04 - acc: 0.9682 - val_loss: 0.0013 - val_acc: 0.9450\n",
            "Epoch 282/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.1341e-04 - acc: 0.9674 - val_loss: 5.7911e-05 - val_acc: 1.0000\n",
            "Epoch 283/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.4455e-04 - acc: 0.9654 - val_loss: 1.0634e-05 - val_acc: 0.9175\n",
            "Epoch 284/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.7520e-04 - acc: 0.9587 - val_loss: 4.6465e-04 - val_acc: 0.9175\n",
            "Epoch 285/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 8.5402e-04 - acc: 0.9619 - val_loss: 6.8403e-06 - val_acc: 0.9725\n",
            "Epoch 286/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.4273e-04 - acc: 0.9580 - val_loss: 9.1556e-05 - val_acc: 0.9175\n",
            "Epoch 287/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.9793e-04 - acc: 0.9595 - val_loss: 6.9020e-04 - val_acc: 1.0000\n",
            "Epoch 288/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.1513e-04 - acc: 0.9548 - val_loss: 5.9479e-06 - val_acc: 0.9725\n",
            "Epoch 289/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.0362e-04 - acc: 0.9591 - val_loss: 1.5692e-05 - val_acc: 1.0000\n",
            "Epoch 290/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 4.4116e-04 - acc: 0.9635 - val_loss: 8.2752e-04 - val_acc: 1.0000\n",
            "Epoch 291/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 7.1374e-04 - acc: 0.9646 - val_loss: 1.8788e-04 - val_acc: 0.9175\n",
            "Epoch 292/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.0279e-04 - acc: 0.9658 - val_loss: 3.0920e-06 - val_acc: 0.9450\n",
            "Epoch 293/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0013 - acc: 0.9583 - val_loss: 6.0304e-06 - val_acc: 0.9175\n",
            "Epoch 294/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.3962e-04 - acc: 0.9513 - val_loss: 3.1063e-05 - val_acc: 0.9725\n",
            "Epoch 295/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.8527e-04 - acc: 0.9521 - val_loss: 0.0019 - val_acc: 0.9450\n",
            "Epoch 296/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.1942e-04 - acc: 0.9603 - val_loss: 1.9197e-04 - val_acc: 0.9175\n",
            "Epoch 297/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 6.1991e-04 - acc: 0.9548 - val_loss: 8.6014e-05 - val_acc: 0.9725\n",
            "Epoch 298/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 5.8856e-04 - acc: 0.9532 - val_loss: 3.9676e-06 - val_acc: 0.9175\n",
            "Epoch 299/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 0.0018 - acc: 0.9446 - val_loss: 3.7610e-05 - val_acc: 1.0000\n",
            "Epoch 300/300\n",
            "2545/2545 [==============================] - 3s 1ms/step - loss: 9.4912e-04 - acc: 0.9572 - val_loss: 9.8556e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iiyrefWy-c_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the encoded representation of the train Data and test Data\n",
        "\n",
        "train_data_Encoded= encoderPart.predict(train_data[:,:2])\n",
        "test_data_Encoded= encoderPart.predict(test_data[:,:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnFXGpob30Z2",
        "colab_type": "code",
        "outputId": "f683fac3-8080-4de7-a3c1-484cc76db1f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_data[0,2]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1232.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD4krONu36bH",
        "colab_type": "code",
        "outputId": "c9ea7481-733a-45d4-ad17-fcb5c3ffd00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_data_Encoded[0,1]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDM-0Atc4Bny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make new train data and test Data\n",
        "newTrainData= []\n",
        "newTestData= []\n",
        "for i in range(train_data.shape[0]):\n",
        "  newTrainData.append([train_data_Encoded[i,0],train_data_Encoded[i,1],train_data[i,2]])\n",
        "  \n",
        "for i in range(test_data.shape[0]):\n",
        "  newTestData.append([test_data_Encoded[i,0],test_data_Encoded[i,1],test_data[i,2]])\n",
        "  \n",
        "newTrainData= np.array(newTrainData)\n",
        "newTestData= np.array(newTestData)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89pr8s-v-mUN",
        "colab_type": "code",
        "outputId": "0920f647-f44e-42bb-d5ea-904a8e094d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "newTrainData.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3636, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gAJ2TdQ_J60",
        "colab_type": "code",
        "outputId": "07abfcf5-ada3-4390-a1a9-ad7e19bd1331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "newTestData.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svje7_5T_SdK",
        "colab_type": "code",
        "outputId": "76e706fb-2ad7-481f-caee-4664fc92c79e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "newTrainData[0,]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.71574503e-02, 0.00000000e+00, 1.23200000e+03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsTXAOfz_XiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build the neural Network for prediction\n",
        "\n",
        "neuralNetwork = Sequential()\n",
        "ip_dim = 2\n",
        "#model.add(Dropout(0.1, input_shape=(ip_dim,))\n",
        "neuralNetwork.add(Dense(10, input_dim=ip_dim, kernel_initializer='normal', activation='relu'))\n",
        "neuralNetwork.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
        "#neuralNetwork.add(Dropout(0.1))\n",
        "neuralNetwork.add(Dense(2, kernel_initializer='normal', activation='relu'))\n",
        "#neuralNetwork.add(Dropout(0.1))\n",
        "#neuralNetwork.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
        "neuralNetwork.add(Dense(1, kernel_initializer='normal',activation=\"exponential\"))\n",
        "# Compile model\n",
        "neuralNetwork.compile(loss=poisson_dev, optimizer='adam',metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l8ImIMnAPKs",
        "colab_type": "code",
        "outputId": "2d30fb59-fa03-41f8-fbb3-7d226d4b3a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17368
        }
      },
      "source": [
        "history = neuralNetwork.fit(x=newTrainData[:,:ip_dim], y=newTrainData[:,ip_dim], batch_size=1, epochs=500, verbose=1, callbacks=None, validation_split=0.33, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2436 samples, validate on 1200 samples\n",
            "Epoch 1/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 12706.3640 - acc: 0.0000e+00 - val_loss: 7168.4000 - val_acc: 0.0000e+00\n",
            "Epoch 2/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 4638.4270 - acc: 0.0000e+00 - val_loss: 1891.9397 - val_acc: 0.0000e+00\n",
            "Epoch 3/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 478.8442 - acc: 4.1051e-04 - val_loss: 268.5317 - val_acc: 8.3333e-04\n",
            "Epoch 4/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 283.1987 - acc: 0.0000e+00 - val_loss: 278.8452 - val_acc: 0.0000e+00\n",
            "Epoch 5/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 283.4959 - acc: 0.0000e+00 - val_loss: 266.2173 - val_acc: 0.0000e+00\n",
            "Epoch 6/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 285.4822 - acc: 0.0000e+00 - val_loss: 314.8965 - val_acc: 0.0000e+00\n",
            "Epoch 7/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 284.9769 - acc: 0.0000e+00 - val_loss: 388.8461 - val_acc: 8.3333e-04\n",
            "Epoch 8/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 288.8810 - acc: 4.1051e-04 - val_loss: 262.9778 - val_acc: 0.0000e+00\n",
            "Epoch 9/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 282.0406 - acc: 0.0000e+00 - val_loss: 274.3223 - val_acc: 0.0000e+00\n",
            "Epoch 10/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 280.4515 - acc: 0.0000e+00 - val_loss: 306.8888 - val_acc: 0.0000e+00\n",
            "Epoch 11/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 284.3312 - acc: 0.0000e+00 - val_loss: 265.0832 - val_acc: 0.0017\n",
            "Epoch 12/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 287.3675 - acc: 0.0000e+00 - val_loss: 286.8523 - val_acc: 0.0000e+00\n",
            "Epoch 13/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 281.1393 - acc: 8.2102e-04 - val_loss: 360.3779 - val_acc: 0.0000e+00\n",
            "Epoch 14/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 283.6568 - acc: 4.1051e-04 - val_loss: 380.3573 - val_acc: 0.0000e+00\n",
            "Epoch 15/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 285.3979 - acc: 4.1051e-04 - val_loss: 372.3226 - val_acc: 0.0000e+00\n",
            "Epoch 16/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 281.4935 - acc: 0.0000e+00 - val_loss: 300.0793 - val_acc: 8.3333e-04\n",
            "Epoch 17/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 281.9562 - acc: 0.0000e+00 - val_loss: 317.4425 - val_acc: 8.3333e-04\n",
            "Epoch 18/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 280.3291 - acc: 0.0000e+00 - val_loss: 254.3158 - val_acc: 0.0000e+00\n",
            "Epoch 19/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 283.1434 - acc: 0.0000e+00 - val_loss: 293.1079 - val_acc: 0.0000e+00\n",
            "Epoch 20/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 284.0314 - acc: 8.2102e-04 - val_loss: 387.2327 - val_acc: 0.0017\n",
            "Epoch 21/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 282.9358 - acc: 0.0000e+00 - val_loss: 294.6657 - val_acc: 0.0000e+00\n",
            "Epoch 22/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 280.1029 - acc: 0.0000e+00 - val_loss: 491.4685 - val_acc: 0.0025\n",
            "Epoch 23/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 283.0861 - acc: 0.0000e+00 - val_loss: 276.1144 - val_acc: 0.0000e+00\n",
            "Epoch 24/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 285.5934 - acc: 0.0000e+00 - val_loss: 259.8837 - val_acc: 8.3333e-04\n",
            "Epoch 25/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 274.5054 - acc: 0.0000e+00 - val_loss: 259.3674 - val_acc: 8.3333e-04\n",
            "Epoch 26/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 283.5767 - acc: 0.0000e+00 - val_loss: 250.2910 - val_acc: 0.0000e+00\n",
            "Epoch 27/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 280.8694 - acc: 4.1051e-04 - val_loss: 359.4545 - val_acc: 0.0000e+00\n",
            "Epoch 28/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 278.5193 - acc: 8.2102e-04 - val_loss: 263.5708 - val_acc: 0.0017\n",
            "Epoch 29/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 279.4648 - acc: 4.1051e-04 - val_loss: 285.4557 - val_acc: 0.0000e+00\n",
            "Epoch 30/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 275.8080 - acc: 4.1051e-04 - val_loss: 255.5185 - val_acc: 8.3333e-04\n",
            "Epoch 31/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 276.2423 - acc: 0.0000e+00 - val_loss: 305.2685 - val_acc: 0.0000e+00\n",
            "Epoch 32/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 279.0443 - acc: 0.0000e+00 - val_loss: 294.2279 - val_acc: 0.0000e+00\n",
            "Epoch 33/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 286.3933 - acc: 0.0000e+00 - val_loss: 266.3651 - val_acc: 0.0000e+00\n",
            "Epoch 34/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 274.9904 - acc: 4.1051e-04 - val_loss: 252.3270 - val_acc: 0.0000e+00\n",
            "Epoch 35/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 278.9108 - acc: 0.0000e+00 - val_loss: 260.2642 - val_acc: 0.0000e+00\n",
            "Epoch 36/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 275.8451 - acc: 0.0000e+00 - val_loss: 262.4388 - val_acc: 0.0000e+00\n",
            "Epoch 37/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 277.6747 - acc: 0.0000e+00 - val_loss: 277.3938 - val_acc: 0.0000e+00\n",
            "Epoch 38/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 279.0809 - acc: 0.0000e+00 - val_loss: 282.2375 - val_acc: 0.0033\n",
            "Epoch 39/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 279.9542 - acc: 4.1051e-04 - val_loss: 264.0318 - val_acc: 0.0000e+00\n",
            "Epoch 40/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 280.4023 - acc: 4.1051e-04 - val_loss: 270.0576 - val_acc: 0.0000e+00\n",
            "Epoch 41/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 270.1709 - acc: 0.0000e+00 - val_loss: 254.9897 - val_acc: 0.0000e+00\n",
            "Epoch 42/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 274.5113 - acc: 0.0000e+00 - val_loss: 250.4333 - val_acc: 8.3333e-04\n",
            "Epoch 43/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 279.5614 - acc: 0.0012 - val_loss: 258.4260 - val_acc: 0.0000e+00\n",
            "Epoch 44/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 270.7371 - acc: 0.0000e+00 - val_loss: 259.9444 - val_acc: 0.0000e+00\n",
            "Epoch 45/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 277.3139 - acc: 8.2102e-04 - val_loss: 348.8805 - val_acc: 0.0000e+00\n",
            "Epoch 46/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 276.6270 - acc: 4.1051e-04 - val_loss: 287.2955 - val_acc: 0.0000e+00\n",
            "Epoch 47/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 276.7351 - acc: 0.0000e+00 - val_loss: 268.3618 - val_acc: 0.0000e+00\n",
            "Epoch 48/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 268.8199 - acc: 0.0000e+00 - val_loss: 259.5921 - val_acc: 0.0000e+00\n",
            "Epoch 49/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 274.3939 - acc: 0.0000e+00 - val_loss: 278.0389 - val_acc: 0.0000e+00\n",
            "Epoch 50/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 268.0648 - acc: 0.0000e+00 - val_loss: 286.2436 - val_acc: 8.3333e-04\n",
            "Epoch 51/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 275.4145 - acc: 0.0000e+00 - val_loss: 272.9459 - val_acc: 0.0000e+00\n",
            "Epoch 52/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 276.9210 - acc: 0.0000e+00 - val_loss: 250.6809 - val_acc: 8.3333e-04\n",
            "Epoch 53/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 272.5851 - acc: 0.0000e+00 - val_loss: 270.9716 - val_acc: 8.3333e-04\n",
            "Epoch 54/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 272.1260 - acc: 4.1051e-04 - val_loss: 257.2811 - val_acc: 0.0000e+00\n",
            "Epoch 55/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 276.7350 - acc: 0.0000e+00 - val_loss: 308.9629 - val_acc: 8.3333e-04\n",
            "Epoch 56/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 273.4221 - acc: 0.0000e+00 - val_loss: 284.4887 - val_acc: 0.0000e+00\n",
            "Epoch 57/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 273.1131 - acc: 0.0000e+00 - val_loss: 264.9729 - val_acc: 0.0000e+00\n",
            "Epoch 58/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 272.1574 - acc: 0.0000e+00 - val_loss: 255.0773 - val_acc: 0.0000e+00\n",
            "Epoch 59/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 272.2553 - acc: 4.1051e-04 - val_loss: 279.8256 - val_acc: 0.0000e+00\n",
            "Epoch 60/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 275.0806 - acc: 4.1051e-04 - val_loss: 284.7457 - val_acc: 0.0033\n",
            "Epoch 61/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 268.4532 - acc: 0.0012 - val_loss: 270.5636 - val_acc: 0.0017\n",
            "Epoch 62/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 271.3360 - acc: 4.1051e-04 - val_loss: 271.4218 - val_acc: 0.0000e+00\n",
            "Epoch 63/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 268.1349 - acc: 0.0000e+00 - val_loss: 313.6921 - val_acc: 0.0033\n",
            "Epoch 64/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 266.0727 - acc: 8.2102e-04 - val_loss: 433.6857 - val_acc: 0.0000e+00\n",
            "Epoch 65/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 274.5608 - acc: 0.0000e+00 - val_loss: 251.8720 - val_acc: 8.3333e-04\n",
            "Epoch 66/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 263.1615 - acc: 4.1051e-04 - val_loss: 541.1485 - val_acc: 0.0025\n",
            "Epoch 67/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 271.2983 - acc: 4.1051e-04 - val_loss: 250.3071 - val_acc: 0.0017\n",
            "Epoch 68/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 264.8936 - acc: 8.2102e-04 - val_loss: 406.1988 - val_acc: 0.0000e+00\n",
            "Epoch 69/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 267.6506 - acc: 0.0000e+00 - val_loss: 275.9747 - val_acc: 0.0000e+00\n",
            "Epoch 70/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 268.1939 - acc: 0.0000e+00 - val_loss: 270.9911 - val_acc: 0.0000e+00\n",
            "Epoch 71/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 267.1670 - acc: 4.1051e-04 - val_loss: 274.3244 - val_acc: 8.3333e-04\n",
            "Epoch 72/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 271.7691 - acc: 4.1051e-04 - val_loss: 275.0657 - val_acc: 8.3333e-04\n",
            "Epoch 73/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 268.9441 - acc: 0.0000e+00 - val_loss: 265.8959 - val_acc: 8.3333e-04\n",
            "Epoch 74/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 268.7278 - acc: 0.0000e+00 - val_loss: 307.3478 - val_acc: 0.0000e+00\n",
            "Epoch 75/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 270.3795 - acc: 4.1051e-04 - val_loss: 296.5903 - val_acc: 0.0000e+00\n",
            "Epoch 76/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 276.5475 - acc: 0.0000e+00 - val_loss: 319.4449 - val_acc: 0.0000e+00\n",
            "Epoch 77/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 267.5969 - acc: 4.1051e-04 - val_loss: 253.0908 - val_acc: 0.0000e+00\n",
            "Epoch 78/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 270.2956 - acc: 4.1051e-04 - val_loss: 293.9099 - val_acc: 0.0000e+00\n",
            "Epoch 79/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 197.6620 - acc: 8.2102e-04 - val_loss: 87.5740 - val_acc: 0.0000e+00\n",
            "Epoch 80/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 84.9359 - acc: 4.1051e-04 - val_loss: 79.0361 - val_acc: 0.0000e+00\n",
            "Epoch 81/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 85.3491 - acc: 8.2102e-04 - val_loss: 87.8626 - val_acc: 0.0000e+00\n",
            "Epoch 82/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 82.4537 - acc: 0.0021 - val_loss: 77.4893 - val_acc: 0.0000e+00\n",
            "Epoch 83/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 84.1701 - acc: 4.1051e-04 - val_loss: 77.1266 - val_acc: 0.0000e+00\n",
            "Epoch 84/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 83.7378 - acc: 8.2102e-04 - val_loss: 106.4349 - val_acc: 8.3333e-04\n",
            "Epoch 85/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 84.1255 - acc: 4.1051e-04 - val_loss: 79.2775 - val_acc: 8.3333e-04\n",
            "Epoch 86/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 83.5101 - acc: 8.2102e-04 - val_loss: 86.6300 - val_acc: 0.0000e+00\n",
            "Epoch 87/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 85.0733 - acc: 8.2102e-04 - val_loss: 91.8494 - val_acc: 0.0000e+00\n",
            "Epoch 88/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 84.8434 - acc: 4.1051e-04 - val_loss: 96.6320 - val_acc: 0.0000e+00\n",
            "Epoch 89/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 82.7964 - acc: 8.2102e-04 - val_loss: 99.4411 - val_acc: 0.0025\n",
            "Epoch 90/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 83.5849 - acc: 0.0000e+00 - val_loss: 82.0863 - val_acc: 0.0000e+00\n",
            "Epoch 91/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 83.6016 - acc: 8.2102e-04 - val_loss: 81.4589 - val_acc: 0.0000e+00\n",
            "Epoch 92/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 84.9559 - acc: 8.2102e-04 - val_loss: 92.8043 - val_acc: 0.0033\n",
            "Epoch 93/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 84.9250 - acc: 0.0000e+00 - val_loss: 78.6147 - val_acc: 0.0000e+00\n",
            "Epoch 94/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 85.0267 - acc: 8.2102e-04 - val_loss: 94.3250 - val_acc: 0.0000e+00\n",
            "Epoch 95/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 83.8745 - acc: 0.0000e+00 - val_loss: 87.9882 - val_acc: 8.3333e-04\n",
            "Epoch 96/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 82.6957 - acc: 0.0012 - val_loss: 87.2180 - val_acc: 0.0000e+00\n",
            "Epoch 97/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 82.5834 - acc: 4.1051e-04 - val_loss: 76.9128 - val_acc: 0.0000e+00\n",
            "Epoch 98/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 82.5683 - acc: 4.1051e-04 - val_loss: 85.3508 - val_acc: 0.0000e+00\n",
            "Epoch 99/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 82.5285 - acc: 8.2102e-04 - val_loss: 112.0387 - val_acc: 0.0000e+00\n",
            "Epoch 100/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 83.8279 - acc: 8.2102e-04 - val_loss: 82.3078 - val_acc: 0.0017\n",
            "Epoch 101/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 81.2440 - acc: 8.2102e-04 - val_loss: 88.9540 - val_acc: 0.0000e+00\n",
            "Epoch 102/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 78.7437 - acc: 4.1051e-04 - val_loss: 102.5589 - val_acc: 8.3333e-04\n",
            "Epoch 103/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 78.0506 - acc: 0.0000e+00 - val_loss: 81.9673 - val_acc: 0.0000e+00\n",
            "Epoch 104/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 78.8363 - acc: 0.0012 - val_loss: 76.9932 - val_acc: 8.3333e-04\n",
            "Epoch 105/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 78.6672 - acc: 0.0012 - val_loss: 77.0844 - val_acc: 0.0000e+00\n",
            "Epoch 106/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 75.9192 - acc: 8.2102e-04 - val_loss: 79.8529 - val_acc: 8.3333e-04\n",
            "Epoch 107/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 75.0770 - acc: 0.0012 - val_loss: 80.6143 - val_acc: 0.0000e+00\n",
            "Epoch 108/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 73.8924 - acc: 0.0000e+00 - val_loss: 64.9152 - val_acc: 0.0000e+00\n",
            "Epoch 109/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 66.3119 - acc: 4.1051e-04 - val_loss: 50.8645 - val_acc: 0.0017\n",
            "Epoch 110/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 35.7194 - acc: 0.0012 - val_loss: 27.0838 - val_acc: 0.0000e+00\n",
            "Epoch 111/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 26.1089 - acc: 0.0000e+00 - val_loss: 28.5982 - val_acc: 0.0000e+00\n",
            "Epoch 112/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 26.5587 - acc: 8.2102e-04 - val_loss: 19.3230 - val_acc: 8.3333e-04\n",
            "Epoch 113/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 22.6140 - acc: 0.0025 - val_loss: 30.6631 - val_acc: 8.3333e-04\n",
            "Epoch 114/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 17.9111 - acc: 8.2102e-04 - val_loss: 12.7048 - val_acc: 8.3333e-04\n",
            "Epoch 115/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 12.6500 - acc: 8.2102e-04 - val_loss: 10.1704 - val_acc: 0.0067\n",
            "Epoch 116/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 9.5797 - acc: 8.2102e-04 - val_loss: 8.5297 - val_acc: 0.0050\n",
            "Epoch 117/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 8.4167 - acc: 0.0029 - val_loss: 8.8519 - val_acc: 8.3333e-04\n",
            "Epoch 118/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 8.3082 - acc: 0.0041 - val_loss: 11.8820 - val_acc: 0.0050\n",
            "Epoch 119/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 8.2168 - acc: 0.0037 - val_loss: 10.0095 - val_acc: 0.0058\n",
            "Epoch 120/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 7.6625 - acc: 0.0029 - val_loss: 32.3002 - val_acc: 0.0000e+00\n",
            "Epoch 121/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 7.5844 - acc: 0.0016 - val_loss: 6.9333 - val_acc: 0.0025\n",
            "Epoch 122/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 7.3325 - acc: 0.0033 - val_loss: 7.5488 - val_acc: 0.0017\n",
            "Epoch 123/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 7.7533 - acc: 0.0033 - val_loss: 10.2562 - val_acc: 8.3333e-04\n",
            "Epoch 124/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 6.9020 - acc: 0.0033 - val_loss: 12.9643 - val_acc: 0.0000e+00\n",
            "Epoch 125/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 6.8672 - acc: 0.0021 - val_loss: 7.6175 - val_acc: 0.0033\n",
            "Epoch 126/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 6.8112 - acc: 0.0041 - val_loss: 27.1907 - val_acc: 0.0017\n",
            "Epoch 127/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 6.7800 - acc: 0.0049 - val_loss: 9.7859 - val_acc: 0.0025\n",
            "Epoch 128/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 6.5483 - acc: 0.0037 - val_loss: 6.4071 - val_acc: 0.0050\n",
            "Epoch 129/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 6.8794 - acc: 0.0029 - val_loss: 8.0632 - val_acc: 0.0033\n",
            "Epoch 130/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 6.6515 - acc: 0.0029 - val_loss: 11.2406 - val_acc: 0.0042\n",
            "Epoch 131/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 6.3519 - acc: 0.0016 - val_loss: 7.6209 - val_acc: 0.0042\n",
            "Epoch 132/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 6.3475 - acc: 0.0025 - val_loss: 7.1747 - val_acc: 0.0042\n",
            "Epoch 133/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 6.4003 - acc: 0.0021 - val_loss: 7.0557 - val_acc: 8.3333e-04\n",
            "Epoch 134/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 5.1433 - acc: 0.0021 - val_loss: 33.0089 - val_acc: 0.0017\n",
            "Epoch 135/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 5.0247 - acc: 0.0041 - val_loss: 25.8560 - val_acc: 0.0000e+00\n",
            "Epoch 136/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 4.4474 - acc: 0.0062 - val_loss: 4.3698 - val_acc: 0.0025\n",
            "Epoch 137/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 4.1818 - acc: 0.0037 - val_loss: 11.5456 - val_acc: 0.0033\n",
            "Epoch 138/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 4.4130 - acc: 0.0037 - val_loss: 5.7143 - val_acc: 0.0058\n",
            "Epoch 139/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 4.1547 - acc: 0.0049 - val_loss: 3.3612 - val_acc: 0.0025\n",
            "Epoch 140/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 4.5619 - acc: 0.0041 - val_loss: 5.9848 - val_acc: 0.0033\n",
            "Epoch 141/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.8970 - acc: 0.0041 - val_loss: 5.4848 - val_acc: 8.3333e-04\n",
            "Epoch 142/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 4.5137 - acc: 0.0033 - val_loss: 4.1483 - val_acc: 0.0075\n",
            "Epoch 143/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 4.3453 - acc: 0.0049 - val_loss: 4.8860 - val_acc: 0.0017\n",
            "Epoch 144/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 4.2480 - acc: 0.0037 - val_loss: 8.3236 - val_acc: 0.0033\n",
            "Epoch 145/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.6452 - acc: 0.0053 - val_loss: 6.1037 - val_acc: 0.0050\n",
            "Epoch 146/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.2644 - acc: 0.0045 - val_loss: 3.2645 - val_acc: 0.0042\n",
            "Epoch 147/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.4344 - acc: 0.0041 - val_loss: 4.1254 - val_acc: 0.0025\n",
            "Epoch 148/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.2436 - acc: 0.0049 - val_loss: 6.7015 - val_acc: 0.0033\n",
            "Epoch 149/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.0253 - acc: 0.0053 - val_loss: 4.0981 - val_acc: 0.0017\n",
            "Epoch 150/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.2593 - acc: 0.0041 - val_loss: 9.0800 - val_acc: 0.0025\n",
            "Epoch 151/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.2086 - acc: 0.0041 - val_loss: 11.4284 - val_acc: 0.0025\n",
            "Epoch 152/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.3384 - acc: 0.0045 - val_loss: 5.4667 - val_acc: 8.3333e-04\n",
            "Epoch 153/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.6389 - acc: 0.0049 - val_loss: 5.5813 - val_acc: 0.0025\n",
            "Epoch 154/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.9556 - acc: 0.0070 - val_loss: 3.1953 - val_acc: 0.0033\n",
            "Epoch 155/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.9905 - acc: 0.0053 - val_loss: 4.5716 - val_acc: 0.0050\n",
            "Epoch 156/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.6839 - acc: 0.0033 - val_loss: 5.0932 - val_acc: 0.0042\n",
            "Epoch 157/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.0569 - acc: 0.0041 - val_loss: 6.3318 - val_acc: 0.0050\n",
            "Epoch 158/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.2560 - acc: 0.0066 - val_loss: 5.8736 - val_acc: 0.0033\n",
            "Epoch 159/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.9114 - acc: 0.0053 - val_loss: 6.6688 - val_acc: 0.0058\n",
            "Epoch 160/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.3118 - acc: 0.0041 - val_loss: 10.4756 - val_acc: 0.0017\n",
            "Epoch 161/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.2748 - acc: 0.0045 - val_loss: 2.6943 - val_acc: 0.0017\n",
            "Epoch 162/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.3887 - acc: 0.0045 - val_loss: 7.8323 - val_acc: 0.0017\n",
            "Epoch 163/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.1793 - acc: 0.0057 - val_loss: 6.3806 - val_acc: 8.3333e-04\n",
            "Epoch 164/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.1255 - acc: 0.0053 - val_loss: 5.3089 - val_acc: 0.0033\n",
            "Epoch 165/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.1232 - acc: 0.0033 - val_loss: 5.1589 - val_acc: 0.0067\n",
            "Epoch 166/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.3777 - acc: 0.0074 - val_loss: 5.5022 - val_acc: 0.0017\n",
            "Epoch 167/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.0970 - acc: 0.0045 - val_loss: 4.6738 - val_acc: 0.0025\n",
            "Epoch 168/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.5347 - acc: 0.0041 - val_loss: 10.2155 - val_acc: 0.0017\n",
            "Epoch 169/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.7305 - acc: 0.0053 - val_loss: 3.8687 - val_acc: 0.0042\n",
            "Epoch 170/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.1438 - acc: 0.0062 - val_loss: 9.0918 - val_acc: 0.0050\n",
            "Epoch 171/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.2020 - acc: 0.0057 - val_loss: 4.5252 - val_acc: 0.0017\n",
            "Epoch 172/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.0734 - acc: 0.0049 - val_loss: 8.1380 - val_acc: 0.0033\n",
            "Epoch 173/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.9959 - acc: 0.0062 - val_loss: 6.2062 - val_acc: 0.0017\n",
            "Epoch 174/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.0491 - acc: 0.0037 - val_loss: 6.8224 - val_acc: 0.0033\n",
            "Epoch 175/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.0043 - acc: 0.0049 - val_loss: 10.1696 - val_acc: 0.0017\n",
            "Epoch 176/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.1486 - acc: 0.0066 - val_loss: 6.5300 - val_acc: 0.0000e+00\n",
            "Epoch 177/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.0360 - acc: 0.0025 - val_loss: 10.0049 - val_acc: 8.3333e-04\n",
            "Epoch 178/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.0415 - acc: 0.0045 - val_loss: 4.4367 - val_acc: 0.0058\n",
            "Epoch 179/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.1784 - acc: 0.0045 - val_loss: 5.8523 - val_acc: 8.3333e-04\n",
            "Epoch 180/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.9473 - acc: 0.0029 - val_loss: 2.9328 - val_acc: 0.0033\n",
            "Epoch 181/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.8528 - acc: 0.0066 - val_loss: 4.7420 - val_acc: 0.0033\n",
            "Epoch 182/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.7965 - acc: 0.0037 - val_loss: 6.6326 - val_acc: 0.0025\n",
            "Epoch 183/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 3.2428 - acc: 0.0057 - val_loss: 10.4934 - val_acc: 8.3333e-04\n",
            "Epoch 184/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.7123 - acc: 0.0045 - val_loss: 17.6207 - val_acc: 0.0025\n",
            "Epoch 185/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.8609 - acc: 0.0041 - val_loss: 7.7132 - val_acc: 0.0050\n",
            "Epoch 186/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.7191 - acc: 0.0070 - val_loss: 13.6163 - val_acc: 0.0042\n",
            "Epoch 187/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.9027 - acc: 0.0049 - val_loss: 2.9024 - val_acc: 0.0050\n",
            "Epoch 188/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5756 - acc: 0.0033 - val_loss: 9.3710 - val_acc: 0.0025\n",
            "Epoch 189/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.8147 - acc: 0.0029 - val_loss: 9.3173 - val_acc: 0.0033\n",
            "Epoch 190/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6222 - acc: 0.0049 - val_loss: 9.9132 - val_acc: 0.0025\n",
            "Epoch 191/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.8216 - acc: 0.0057 - val_loss: 7.4495 - val_acc: 8.3333e-04\n",
            "Epoch 192/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6053 - acc: 0.0074 - val_loss: 5.3081 - val_acc: 0.0025\n",
            "Epoch 193/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6168 - acc: 0.0053 - val_loss: 12.0550 - val_acc: 8.3333e-04\n",
            "Epoch 194/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.8962 - acc: 0.0066 - val_loss: 10.2825 - val_acc: 0.0000e+00\n",
            "Epoch 195/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4572 - acc: 0.0045 - val_loss: 6.6192 - val_acc: 8.3333e-04\n",
            "Epoch 196/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.7758 - acc: 0.0053 - val_loss: 9.7984 - val_acc: 8.3333e-04\n",
            "Epoch 197/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5610 - acc: 0.0053 - val_loss: 3.2581 - val_acc: 8.3333e-04\n",
            "Epoch 198/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.7380 - acc: 0.0037 - val_loss: 6.9122 - val_acc: 0.0025\n",
            "Epoch 199/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6750 - acc: 0.0053 - val_loss: 7.1789 - val_acc: 0.0017\n",
            "Epoch 200/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6395 - acc: 0.0074 - val_loss: 6.4676 - val_acc: 0.0025\n",
            "Epoch 201/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6150 - acc: 0.0045 - val_loss: 7.5889 - val_acc: 0.0017\n",
            "Epoch 202/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4512 - acc: 0.0070 - val_loss: 4.6518 - val_acc: 0.0017\n",
            "Epoch 203/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6638 - acc: 0.0041 - val_loss: 4.5623 - val_acc: 0.0125\n",
            "Epoch 204/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3982 - acc: 0.0045 - val_loss: 5.9799 - val_acc: 0.0033\n",
            "Epoch 205/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6566 - acc: 0.0049 - val_loss: 4.6796 - val_acc: 0.0017\n",
            "Epoch 206/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.7005 - acc: 0.0037 - val_loss: 4.0634 - val_acc: 0.0025\n",
            "Epoch 207/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.7115 - acc: 0.0062 - val_loss: 14.4163 - val_acc: 0.0000e+00\n",
            "Epoch 208/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6492 - acc: 0.0045 - val_loss: 2.6966 - val_acc: 0.0058\n",
            "Epoch 209/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.7518 - acc: 0.0057 - val_loss: 5.3255 - val_acc: 0.0042\n",
            "Epoch 210/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5273 - acc: 0.0041 - val_loss: 4.8727 - val_acc: 0.0025\n",
            "Epoch 211/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3372 - acc: 0.0070 - val_loss: 6.2427 - val_acc: 0.0058\n",
            "Epoch 212/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6903 - acc: 0.0033 - val_loss: 9.1021 - val_acc: 0.0000e+00\n",
            "Epoch 213/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5453 - acc: 0.0053 - val_loss: 6.7628 - val_acc: 0.0033\n",
            "Epoch 214/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6561 - acc: 0.0045 - val_loss: 6.3745 - val_acc: 0.0050\n",
            "Epoch 215/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4932 - acc: 0.0037 - val_loss: 8.5094 - val_acc: 8.3333e-04\n",
            "Epoch 216/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4237 - acc: 0.0066 - val_loss: 7.1254 - val_acc: 0.0025\n",
            "Epoch 217/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3194 - acc: 0.0045 - val_loss: 4.0181 - val_acc: 0.0058\n",
            "Epoch 218/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4527 - acc: 0.0053 - val_loss: 14.1775 - val_acc: 0.0000e+00\n",
            "Epoch 219/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4023 - acc: 0.0053 - val_loss: 6.2239 - val_acc: 0.0033\n",
            "Epoch 220/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3762 - acc: 0.0057 - val_loss: 3.0696 - val_acc: 0.0058\n",
            "Epoch 221/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6052 - acc: 0.0049 - val_loss: 2.1813 - val_acc: 0.0058\n",
            "Epoch 222/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4902 - acc: 0.0049 - val_loss: 4.1310 - val_acc: 0.0017\n",
            "Epoch 223/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5098 - acc: 0.0033 - val_loss: 7.0647 - val_acc: 0.0033\n",
            "Epoch 224/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3581 - acc: 0.0062 - val_loss: 9.8370 - val_acc: 8.3333e-04\n",
            "Epoch 225/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3687 - acc: 0.0066 - val_loss: 8.1211 - val_acc: 0.0025\n",
            "Epoch 226/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5328 - acc: 0.0078 - val_loss: 4.8806 - val_acc: 0.0000e+00\n",
            "Epoch 227/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2940 - acc: 0.0070 - val_loss: 2.9028 - val_acc: 0.0042\n",
            "Epoch 228/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.6717 - acc: 0.0062 - val_loss: 9.8387 - val_acc: 0.0000e+00\n",
            "Epoch 229/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5953 - acc: 0.0041 - val_loss: 4.3351 - val_acc: 0.0050\n",
            "Epoch 230/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2244 - acc: 0.0062 - val_loss: 4.4418 - val_acc: 0.0025\n",
            "Epoch 231/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5786 - acc: 0.0037 - val_loss: 12.4032 - val_acc: 0.0000e+00\n",
            "Epoch 232/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3001 - acc: 0.0074 - val_loss: 4.3479 - val_acc: 0.0025\n",
            "Epoch 233/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3860 - acc: 0.0066 - val_loss: 7.2629 - val_acc: 8.3333e-04\n",
            "Epoch 234/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4841 - acc: 0.0029 - val_loss: 12.0464 - val_acc: 8.3333e-04\n",
            "Epoch 235/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3504 - acc: 0.0029 - val_loss: 4.1423 - val_acc: 0.0050\n",
            "Epoch 236/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.7858 - acc: 0.0049 - val_loss: 7.4559 - val_acc: 0.0042\n",
            "Epoch 237/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4249 - acc: 0.0033 - val_loss: 6.5468 - val_acc: 0.0025\n",
            "Epoch 238/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3578 - acc: 0.0049 - val_loss: 3.9574 - val_acc: 0.0025\n",
            "Epoch 239/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4386 - acc: 0.0037 - val_loss: 5.7886 - val_acc: 0.0033\n",
            "Epoch 240/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4370 - acc: 0.0033 - val_loss: 4.1015 - val_acc: 0.0050\n",
            "Epoch 241/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3965 - acc: 0.0045 - val_loss: 3.9936 - val_acc: 0.0025\n",
            "Epoch 242/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3408 - acc: 0.0033 - val_loss: 7.4990 - val_acc: 0.0033\n",
            "Epoch 243/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3322 - acc: 0.0041 - val_loss: 3.0085 - val_acc: 0.0125\n",
            "Epoch 244/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5206 - acc: 0.0053 - val_loss: 7.8646 - val_acc: 0.0042\n",
            "Epoch 245/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4402 - acc: 0.0057 - val_loss: 4.6087 - val_acc: 0.0058\n",
            "Epoch 246/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4137 - acc: 0.0057 - val_loss: 6.1858 - val_acc: 0.0017\n",
            "Epoch 247/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3194 - acc: 0.0033 - val_loss: 10.9417 - val_acc: 0.0000e+00\n",
            "Epoch 248/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5417 - acc: 0.0082 - val_loss: 5.3418 - val_acc: 0.0025\n",
            "Epoch 249/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3656 - acc: 0.0053 - val_loss: 5.0584 - val_acc: 0.0000e+00\n",
            "Epoch 250/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4807 - acc: 0.0049 - val_loss: 4.8479 - val_acc: 0.0025\n",
            "Epoch 251/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4034 - acc: 0.0041 - val_loss: 7.3775 - val_acc: 0.0025\n",
            "Epoch 252/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4089 - acc: 0.0062 - val_loss: 6.2623 - val_acc: 0.0017\n",
            "Epoch 253/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4167 - acc: 0.0053 - val_loss: 4.2574 - val_acc: 0.0033\n",
            "Epoch 254/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4353 - acc: 0.0066 - val_loss: 3.7091 - val_acc: 0.0033\n",
            "Epoch 255/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3525 - acc: 0.0049 - val_loss: 5.4956 - val_acc: 0.0050\n",
            "Epoch 256/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4709 - acc: 0.0057 - val_loss: 8.0564 - val_acc: 8.3333e-04\n",
            "Epoch 257/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3513 - acc: 0.0057 - val_loss: 4.6949 - val_acc: 0.0033\n",
            "Epoch 258/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3028 - acc: 0.0062 - val_loss: 2.8184 - val_acc: 0.0017\n",
            "Epoch 259/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4082 - acc: 0.0062 - val_loss: 6.4300 - val_acc: 8.3333e-04\n",
            "Epoch 260/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3713 - acc: 0.0086 - val_loss: 12.7227 - val_acc: 0.0025\n",
            "Epoch 261/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2952 - acc: 0.0041 - val_loss: 11.9881 - val_acc: 0.0000e+00\n",
            "Epoch 262/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3034 - acc: 0.0082 - val_loss: 4.0446 - val_acc: 0.0083\n",
            "Epoch 263/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3329 - acc: 0.0049 - val_loss: 5.6475 - val_acc: 0.0033\n",
            "Epoch 264/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2371 - acc: 0.0078 - val_loss: 10.9839 - val_acc: 8.3333e-04\n",
            "Epoch 265/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3915 - acc: 0.0053 - val_loss: 3.4083 - val_acc: 0.0067\n",
            "Epoch 266/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3406 - acc: 0.0062 - val_loss: 4.9954 - val_acc: 0.0017\n",
            "Epoch 267/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3116 - acc: 0.0029 - val_loss: 5.4778 - val_acc: 0.0025\n",
            "Epoch 268/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4218 - acc: 0.0041 - val_loss: 6.1947 - val_acc: 8.3333e-04\n",
            "Epoch 269/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3506 - acc: 0.0045 - val_loss: 9.5697 - val_acc: 0.0033\n",
            "Epoch 270/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2320 - acc: 0.0090 - val_loss: 9.3612 - val_acc: 0.0025\n",
            "Epoch 271/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2765 - acc: 0.0045 - val_loss: 3.8093 - val_acc: 0.0033\n",
            "Epoch 272/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2130 - acc: 0.0041 - val_loss: 11.5320 - val_acc: 0.0017\n",
            "Epoch 273/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2386 - acc: 0.0049 - val_loss: 11.9481 - val_acc: 8.3333e-04\n",
            "Epoch 274/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3296 - acc: 0.0053 - val_loss: 7.3490 - val_acc: 0.0017\n",
            "Epoch 275/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4239 - acc: 0.0057 - val_loss: 10.6124 - val_acc: 0.0000e+00\n",
            "Epoch 276/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1360 - acc: 0.0049 - val_loss: 8.3971 - val_acc: 8.3333e-04\n",
            "Epoch 277/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3022 - acc: 0.0029 - val_loss: 6.4493 - val_acc: 0.0025\n",
            "Epoch 278/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.5148 - acc: 0.0025 - val_loss: 2.7097 - val_acc: 0.0025\n",
            "Epoch 279/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0942 - acc: 0.0049 - val_loss: 7.1586 - val_acc: 0.0025\n",
            "Epoch 280/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4446 - acc: 0.0049 - val_loss: 6.1256 - val_acc: 0.0000e+00\n",
            "Epoch 281/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1539 - acc: 0.0049 - val_loss: 10.0594 - val_acc: 0.0000e+00\n",
            "Epoch 282/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2551 - acc: 0.0070 - val_loss: 6.4005 - val_acc: 8.3333e-04\n",
            "Epoch 283/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4446 - acc: 0.0057 - val_loss: 4.6321 - val_acc: 0.0075\n",
            "Epoch 284/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2260 - acc: 0.0049 - val_loss: 6.5051 - val_acc: 0.0017\n",
            "Epoch 285/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1128 - acc: 0.0045 - val_loss: 3.5290 - val_acc: 0.0067\n",
            "Epoch 286/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3332 - acc: 0.0070 - val_loss: 5.2444 - val_acc: 8.3333e-04\n",
            "Epoch 287/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4647 - acc: 0.0053 - val_loss: 3.4760 - val_acc: 0.0075\n",
            "Epoch 288/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3004 - acc: 0.0049 - val_loss: 9.9592 - val_acc: 0.0042\n",
            "Epoch 289/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3051 - acc: 0.0033 - val_loss: 6.9896 - val_acc: 0.0000e+00\n",
            "Epoch 290/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2417 - acc: 0.0070 - val_loss: 4.5702 - val_acc: 8.3333e-04\n",
            "Epoch 291/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2712 - acc: 0.0037 - val_loss: 16.4300 - val_acc: 0.0033\n",
            "Epoch 292/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4549 - acc: 0.0033 - val_loss: 7.2691 - val_acc: 0.0000e+00\n",
            "Epoch 293/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3409 - acc: 0.0049 - val_loss: 10.5068 - val_acc: 0.0033\n",
            "Epoch 294/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3600 - acc: 0.0066 - val_loss: 6.1126 - val_acc: 0.0000e+00\n",
            "Epoch 295/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2311 - acc: 0.0037 - val_loss: 5.6286 - val_acc: 0.0025\n",
            "Epoch 296/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2197 - acc: 0.0074 - val_loss: 8.2973 - val_acc: 0.0017\n",
            "Epoch 297/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2951 - acc: 0.0066 - val_loss: 9.7545 - val_acc: 0.0017\n",
            "Epoch 298/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2269 - acc: 0.0057 - val_loss: 8.3515 - val_acc: 0.0033\n",
            "Epoch 299/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2323 - acc: 0.0045 - val_loss: 3.9577 - val_acc: 0.0000e+00\n",
            "Epoch 300/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3674 - acc: 0.0049 - val_loss: 5.6348 - val_acc: 0.0033\n",
            "Epoch 301/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2471 - acc: 0.0057 - val_loss: 4.9183 - val_acc: 0.0042\n",
            "Epoch 302/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1891 - acc: 0.0078 - val_loss: 7.5255 - val_acc: 0.0033\n",
            "Epoch 303/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0442 - acc: 0.0057 - val_loss: 6.4766 - val_acc: 0.0000e+00\n",
            "Epoch 304/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3530 - acc: 0.0045 - val_loss: 3.2585 - val_acc: 0.0075\n",
            "Epoch 305/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1820 - acc: 0.0057 - val_loss: 9.2888 - val_acc: 0.0017\n",
            "Epoch 306/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2345 - acc: 0.0062 - val_loss: 6.9182 - val_acc: 0.0025\n",
            "Epoch 307/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1833 - acc: 0.0041 - val_loss: 5.1371 - val_acc: 0.0025\n",
            "Epoch 308/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4724 - acc: 0.0057 - val_loss: 5.6812 - val_acc: 0.0025\n",
            "Epoch 309/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0426 - acc: 0.0094 - val_loss: 4.0609 - val_acc: 0.0058\n",
            "Epoch 310/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2999 - acc: 0.0033 - val_loss: 4.8344 - val_acc: 0.0058\n",
            "Epoch 311/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.4588 - acc: 0.0062 - val_loss: 5.5671 - val_acc: 0.0025\n",
            "Epoch 312/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3119 - acc: 0.0049 - val_loss: 5.5218 - val_acc: 8.3333e-04\n",
            "Epoch 313/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1941 - acc: 0.0033 - val_loss: 7.1571 - val_acc: 8.3333e-04\n",
            "Epoch 314/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0449 - acc: 0.0029 - val_loss: 3.6221 - val_acc: 0.0092\n",
            "Epoch 315/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0909 - acc: 0.0053 - val_loss: 4.3074 - val_acc: 8.3333e-04\n",
            "Epoch 316/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2511 - acc: 0.0049 - val_loss: 4.3754 - val_acc: 8.3333e-04\n",
            "Epoch 317/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2053 - acc: 0.0049 - val_loss: 7.0983 - val_acc: 0.0017\n",
            "Epoch 318/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2231 - acc: 0.0062 - val_loss: 3.4931 - val_acc: 0.0058\n",
            "Epoch 319/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1475 - acc: 0.0057 - val_loss: 4.9655 - val_acc: 0.0033\n",
            "Epoch 320/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2232 - acc: 0.0074 - val_loss: 6.9171 - val_acc: 8.3333e-04\n",
            "Epoch 321/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1809 - acc: 0.0066 - val_loss: 6.3727 - val_acc: 0.0017\n",
            "Epoch 322/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1757 - acc: 0.0033 - val_loss: 7.6542 - val_acc: 0.0000e+00\n",
            "Epoch 323/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2538 - acc: 0.0029 - val_loss: 6.9618 - val_acc: 0.0017\n",
            "Epoch 324/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2938 - acc: 0.0049 - val_loss: 5.8565 - val_acc: 0.0067\n",
            "Epoch 325/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2828 - acc: 0.0053 - val_loss: 7.5441 - val_acc: 0.0050\n",
            "Epoch 326/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1605 - acc: 0.0066 - val_loss: 6.3789 - val_acc: 0.0033\n",
            "Epoch 327/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0857 - acc: 0.0066 - val_loss: 4.8234 - val_acc: 0.0050\n",
            "Epoch 328/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0065 - acc: 0.0041 - val_loss: 8.4261 - val_acc: 0.0042\n",
            "Epoch 329/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1473 - acc: 0.0029 - val_loss: 3.3511 - val_acc: 0.0050\n",
            "Epoch 330/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2325 - acc: 0.0045 - val_loss: 5.7233 - val_acc: 0.0025\n",
            "Epoch 331/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2519 - acc: 0.0070 - val_loss: 13.2255 - val_acc: 0.0050\n",
            "Epoch 332/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1661 - acc: 0.0053 - val_loss: 2.4697 - val_acc: 0.0075\n",
            "Epoch 333/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0017 - acc: 0.0057 - val_loss: 5.8029 - val_acc: 0.0042\n",
            "Epoch 334/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0643 - acc: 0.0045 - val_loss: 6.7028 - val_acc: 8.3333e-04\n",
            "Epoch 335/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1885 - acc: 0.0053 - val_loss: 9.7457 - val_acc: 0.0000e+00\n",
            "Epoch 336/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3726 - acc: 0.0053 - val_loss: 5.4195 - val_acc: 0.0033\n",
            "Epoch 337/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1950 - acc: 0.0049 - val_loss: 10.7366 - val_acc: 0.0050\n",
            "Epoch 338/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1805 - acc: 0.0066 - val_loss: 3.8128 - val_acc: 0.0033\n",
            "Epoch 339/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2942 - acc: 0.0070 - val_loss: 4.4227 - val_acc: 0.0058\n",
            "Epoch 340/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1126 - acc: 0.0049 - val_loss: 6.0573 - val_acc: 0.0025\n",
            "Epoch 341/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1789 - acc: 0.0037 - val_loss: 9.6644 - val_acc: 0.0000e+00\n",
            "Epoch 342/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0344 - acc: 0.0074 - val_loss: 4.2534 - val_acc: 8.3333e-04\n",
            "Epoch 343/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2408 - acc: 0.0066 - val_loss: 2.7193 - val_acc: 0.0042\n",
            "Epoch 344/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2081 - acc: 0.0074 - val_loss: 3.8490 - val_acc: 0.0058\n",
            "Epoch 345/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1089 - acc: 0.0066 - val_loss: 10.5995 - val_acc: 0.0000e+00\n",
            "Epoch 346/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1133 - acc: 0.0082 - val_loss: 5.1088 - val_acc: 0.0058\n",
            "Epoch 347/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0719 - acc: 0.0049 - val_loss: 7.2021 - val_acc: 0.0025\n",
            "Epoch 348/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0367 - acc: 0.0041 - val_loss: 10.6511 - val_acc: 8.3333e-04\n",
            "Epoch 349/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0086 - acc: 0.0016 - val_loss: 7.8159 - val_acc: 0.0050\n",
            "Epoch 350/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0858 - acc: 0.0029 - val_loss: 9.9750 - val_acc: 0.0025\n",
            "Epoch 351/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1665 - acc: 0.0041 - val_loss: 6.7877 - val_acc: 0.0000e+00\n",
            "Epoch 352/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.3562 - acc: 0.0037 - val_loss: 4.2786 - val_acc: 0.0067\n",
            "Epoch 353/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0692 - acc: 0.0070 - val_loss: 3.7011 - val_acc: 0.0025\n",
            "Epoch 354/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1282 - acc: 0.0045 - val_loss: 5.6543 - val_acc: 0.0033\n",
            "Epoch 355/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2096 - acc: 0.0053 - val_loss: 10.4910 - val_acc: 0.0000e+00\n",
            "Epoch 356/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0399 - acc: 0.0078 - val_loss: 4.8419 - val_acc: 0.0025\n",
            "Epoch 357/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0121 - acc: 0.0115 - val_loss: 4.1516 - val_acc: 0.0083\n",
            "Epoch 358/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1378 - acc: 0.0053 - val_loss: 4.2429 - val_acc: 0.0042\n",
            "Epoch 359/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1373 - acc: 0.0078 - val_loss: 5.8337 - val_acc: 0.0025\n",
            "Epoch 360/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9497 - acc: 0.0066 - val_loss: 6.8055 - val_acc: 0.0033\n",
            "Epoch 361/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9082 - acc: 0.0066 - val_loss: 2.6731 - val_acc: 0.0100\n",
            "Epoch 362/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2074 - acc: 0.0078 - val_loss: 5.9544 - val_acc: 0.0033\n",
            "Epoch 363/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0318 - acc: 0.0041 - val_loss: 2.8296 - val_acc: 0.0083\n",
            "Epoch 364/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0117 - acc: 0.0049 - val_loss: 6.3084 - val_acc: 0.0000e+00\n",
            "Epoch 365/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2523 - acc: 0.0074 - val_loss: 5.7380 - val_acc: 8.3333e-04\n",
            "Epoch 366/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0621 - acc: 0.0049 - val_loss: 6.7407 - val_acc: 0.0050\n",
            "Epoch 367/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1342 - acc: 0.0070 - val_loss: 6.6168 - val_acc: 0.0017\n",
            "Epoch 368/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9417 - acc: 0.0070 - val_loss: 3.2546 - val_acc: 0.0050\n",
            "Epoch 369/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2607 - acc: 0.0037 - val_loss: 6.4532 - val_acc: 8.3333e-04\n",
            "Epoch 370/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0606 - acc: 0.0074 - val_loss: 3.9039 - val_acc: 0.0025\n",
            "Epoch 371/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1156 - acc: 0.0062 - val_loss: 9.0267 - val_acc: 8.3333e-04\n",
            "Epoch 372/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2826 - acc: 0.0041 - val_loss: 4.2178 - val_acc: 0.0033\n",
            "Epoch 373/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0986 - acc: 0.0062 - val_loss: 6.9177 - val_acc: 0.0017\n",
            "Epoch 374/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9723 - acc: 0.0062 - val_loss: 4.6814 - val_acc: 0.0025\n",
            "Epoch 375/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9764 - acc: 0.0037 - val_loss: 6.9929 - val_acc: 0.0042\n",
            "Epoch 376/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.2464 - acc: 0.0037 - val_loss: 9.2055 - val_acc: 0.0000e+00\n",
            "Epoch 377/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1823 - acc: 0.0057 - val_loss: 4.5208 - val_acc: 0.0017\n",
            "Epoch 378/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0697 - acc: 0.0049 - val_loss: 4.9381 - val_acc: 0.0042\n",
            "Epoch 379/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1454 - acc: 0.0062 - val_loss: 2.7037 - val_acc: 0.0033\n",
            "Epoch 380/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9611 - acc: 0.0053 - val_loss: 8.3409 - val_acc: 0.0000e+00\n",
            "Epoch 381/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1281 - acc: 0.0041 - val_loss: 3.8787 - val_acc: 0.0025\n",
            "Epoch 382/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0714 - acc: 0.0057 - val_loss: 10.3005 - val_acc: 0.0042\n",
            "Epoch 383/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0275 - acc: 0.0086 - val_loss: 9.3021 - val_acc: 0.0000e+00\n",
            "Epoch 384/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9915 - acc: 0.0094 - val_loss: 11.5444 - val_acc: 8.3333e-04\n",
            "Epoch 385/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1078 - acc: 0.0033 - val_loss: 7.9086 - val_acc: 0.0025\n",
            "Epoch 386/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9934 - acc: 0.0078 - val_loss: 11.6655 - val_acc: 0.0000e+00\n",
            "Epoch 387/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9255 - acc: 0.0053 - val_loss: 5.5426 - val_acc: 0.0075\n",
            "Epoch 388/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1590 - acc: 0.0070 - val_loss: 3.0474 - val_acc: 0.0083\n",
            "Epoch 389/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1935 - acc: 0.0086 - val_loss: 5.4019 - val_acc: 0.0017\n",
            "Epoch 390/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8217 - acc: 0.0078 - val_loss: 3.6662 - val_acc: 0.0050\n",
            "Epoch 391/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0528 - acc: 0.0074 - val_loss: 7.3790 - val_acc: 0.0033\n",
            "Epoch 392/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0727 - acc: 0.0049 - val_loss: 6.1282 - val_acc: 0.0042\n",
            "Epoch 393/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9909 - acc: 0.0062 - val_loss: 4.0430 - val_acc: 0.0025\n",
            "Epoch 394/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0957 - acc: 0.0053 - val_loss: 10.8001 - val_acc: 0.0033\n",
            "Epoch 395/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0408 - acc: 0.0045 - val_loss: 5.7299 - val_acc: 0.0000e+00\n",
            "Epoch 396/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8563 - acc: 0.0070 - val_loss: 3.0239 - val_acc: 0.0100\n",
            "Epoch 397/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.1000 - acc: 0.0062 - val_loss: 5.6601 - val_acc: 8.3333e-04\n",
            "Epoch 398/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9495 - acc: 0.0078 - val_loss: 13.5994 - val_acc: 0.0042\n",
            "Epoch 399/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0178 - acc: 0.0053 - val_loss: 4.8014 - val_acc: 0.0083\n",
            "Epoch 400/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9095 - acc: 0.0078 - val_loss: 4.2799 - val_acc: 0.0067\n",
            "Epoch 401/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0785 - acc: 0.0049 - val_loss: 12.8434 - val_acc: 8.3333e-04\n",
            "Epoch 402/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9518 - acc: 0.0090 - val_loss: 4.2620 - val_acc: 0.0042\n",
            "Epoch 403/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8345 - acc: 0.0049 - val_loss: 5.6468 - val_acc: 0.0042\n",
            "Epoch 404/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9147 - acc: 0.0045 - val_loss: 8.8041 - val_acc: 0.0033\n",
            "Epoch 405/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9043 - acc: 0.0070 - val_loss: 8.9423 - val_acc: 0.0033\n",
            "Epoch 406/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9252 - acc: 0.0062 - val_loss: 6.0800 - val_acc: 0.0017\n",
            "Epoch 407/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8906 - acc: 0.0066 - val_loss: 2.9229 - val_acc: 0.0017\n",
            "Epoch 408/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8039 - acc: 0.0041 - val_loss: 7.4998 - val_acc: 8.3333e-04\n",
            "Epoch 409/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9058 - acc: 0.0066 - val_loss: 6.5501 - val_acc: 0.0033\n",
            "Epoch 410/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9319 - acc: 0.0066 - val_loss: 2.7746 - val_acc: 8.3333e-04\n",
            "Epoch 411/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9518 - acc: 0.0070 - val_loss: 5.9005 - val_acc: 0.0042\n",
            "Epoch 412/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9854 - acc: 0.0053 - val_loss: 9.7607 - val_acc: 0.0033\n",
            "Epoch 413/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8097 - acc: 0.0045 - val_loss: 4.6390 - val_acc: 0.0042\n",
            "Epoch 414/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0024 - acc: 0.0078 - val_loss: 3.0799 - val_acc: 0.0050\n",
            "Epoch 415/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8613 - acc: 0.0053 - val_loss: 11.0613 - val_acc: 0.0000e+00\n",
            "Epoch 416/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 2.0253 - acc: 0.0078 - val_loss: 5.0711 - val_acc: 0.0033\n",
            "Epoch 417/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8980 - acc: 0.0062 - val_loss: 7.4959 - val_acc: 0.0017\n",
            "Epoch 418/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8921 - acc: 0.0066 - val_loss: 10.9265 - val_acc: 0.0017\n",
            "Epoch 419/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9408 - acc: 0.0074 - val_loss: 4.0804 - val_acc: 0.0067\n",
            "Epoch 420/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9026 - acc: 0.0057 - val_loss: 2.9093 - val_acc: 0.0058\n",
            "Epoch 421/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9041 - acc: 0.0045 - val_loss: 7.1196 - val_acc: 8.3333e-04\n",
            "Epoch 422/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8506 - acc: 0.0062 - val_loss: 8.3471 - val_acc: 0.0042\n",
            "Epoch 423/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6976 - acc: 0.0062 - val_loss: 6.0335 - val_acc: 0.0017\n",
            "Epoch 424/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8267 - acc: 0.0045 - val_loss: 4.2066 - val_acc: 0.0025\n",
            "Epoch 425/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7759 - acc: 0.0053 - val_loss: 5.5443 - val_acc: 0.0000e+00\n",
            "Epoch 426/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8709 - acc: 0.0053 - val_loss: 3.9819 - val_acc: 0.0083\n",
            "Epoch 427/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7550 - acc: 0.0045 - val_loss: 4.9355 - val_acc: 0.0025\n",
            "Epoch 428/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7783 - acc: 0.0049 - val_loss: 4.1727 - val_acc: 0.0033\n",
            "Epoch 429/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8468 - acc: 0.0090 - val_loss: 3.4525 - val_acc: 0.0000e+00\n",
            "Epoch 430/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7635 - acc: 0.0062 - val_loss: 4.9887 - val_acc: 0.0050\n",
            "Epoch 431/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7424 - acc: 0.0070 - val_loss: 4.1371 - val_acc: 0.0025\n",
            "Epoch 432/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7475 - acc: 0.0066 - val_loss: 4.1092 - val_acc: 0.0050\n",
            "Epoch 433/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6115 - acc: 0.0057 - val_loss: 5.5947 - val_acc: 0.0033\n",
            "Epoch 434/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7435 - acc: 0.0066 - val_loss: 6.9973 - val_acc: 0.0033\n",
            "Epoch 435/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7238 - acc: 0.0057 - val_loss: 11.3951 - val_acc: 0.0000e+00\n",
            "Epoch 436/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8257 - acc: 0.0062 - val_loss: 2.6838 - val_acc: 0.0033\n",
            "Epoch 437/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9180 - acc: 0.0086 - val_loss: 5.6568 - val_acc: 0.0042\n",
            "Epoch 438/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.5852 - acc: 0.0070 - val_loss: 3.4319 - val_acc: 0.0117\n",
            "Epoch 439/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6841 - acc: 0.0074 - val_loss: 6.3305 - val_acc: 0.0017\n",
            "Epoch 440/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7327 - acc: 0.0041 - val_loss: 7.5062 - val_acc: 0.0092\n",
            "Epoch 441/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8499 - acc: 0.0066 - val_loss: 7.5080 - val_acc: 0.0042\n",
            "Epoch 442/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7889 - acc: 0.0053 - val_loss: 10.6345 - val_acc: 8.3333e-04\n",
            "Epoch 443/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6834 - acc: 0.0070 - val_loss: 5.5404 - val_acc: 0.0042\n",
            "Epoch 444/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6841 - acc: 0.0062 - val_loss: 2.1444 - val_acc: 0.0058\n",
            "Epoch 445/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7677 - acc: 0.0094 - val_loss: 7.2028 - val_acc: 8.3333e-04\n",
            "Epoch 446/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7705 - acc: 0.0066 - val_loss: 7.4997 - val_acc: 0.0017\n",
            "Epoch 447/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7443 - acc: 0.0074 - val_loss: 5.5287 - val_acc: 0.0042\n",
            "Epoch 448/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7458 - acc: 0.0062 - val_loss: 4.6054 - val_acc: 8.3333e-04\n",
            "Epoch 449/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6701 - acc: 0.0078 - val_loss: 2.7509 - val_acc: 0.0083\n",
            "Epoch 450/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6818 - acc: 0.0062 - val_loss: 6.8980 - val_acc: 0.0017\n",
            "Epoch 451/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7956 - acc: 0.0041 - val_loss: 4.2051 - val_acc: 0.0025\n",
            "Epoch 452/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6132 - acc: 0.0053 - val_loss: 5.9354 - val_acc: 0.0058\n",
            "Epoch 453/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7044 - acc: 0.0045 - val_loss: 7.0363 - val_acc: 0.0017\n",
            "Epoch 454/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7801 - acc: 0.0062 - val_loss: 3.7494 - val_acc: 0.0058\n",
            "Epoch 455/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8006 - acc: 0.0074 - val_loss: 4.4383 - val_acc: 8.3333e-04\n",
            "Epoch 456/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7196 - acc: 0.0082 - val_loss: 3.2856 - val_acc: 0.0050\n",
            "Epoch 457/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7115 - acc: 0.0062 - val_loss: 4.0978 - val_acc: 0.0025\n",
            "Epoch 458/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6717 - acc: 0.0066 - val_loss: 4.5270 - val_acc: 0.0075\n",
            "Epoch 459/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6954 - acc: 0.0090 - val_loss: 3.2481 - val_acc: 0.0067\n",
            "Epoch 460/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6308 - acc: 0.0078 - val_loss: 3.9161 - val_acc: 0.0033\n",
            "Epoch 461/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6049 - acc: 0.0094 - val_loss: 5.1117 - val_acc: 0.0050\n",
            "Epoch 462/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7802 - acc: 0.0082 - val_loss: 7.5969 - val_acc: 0.0017\n",
            "Epoch 463/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7265 - acc: 0.0057 - val_loss: 7.1546 - val_acc: 0.0033\n",
            "Epoch 464/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.9047 - acc: 0.0082 - val_loss: 3.3251 - val_acc: 0.0025\n",
            "Epoch 465/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6906 - acc: 0.0057 - val_loss: 6.2846 - val_acc: 0.0033\n",
            "Epoch 466/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7421 - acc: 0.0033 - val_loss: 3.4572 - val_acc: 0.0100\n",
            "Epoch 467/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7544 - acc: 0.0057 - val_loss: 3.6322 - val_acc: 0.0000e+00\n",
            "Epoch 468/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7600 - acc: 0.0045 - val_loss: 4.8060 - val_acc: 0.0058\n",
            "Epoch 469/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.5729 - acc: 0.0057 - val_loss: 4.6123 - val_acc: 8.3333e-04\n",
            "Epoch 470/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7638 - acc: 0.0057 - val_loss: 5.2361 - val_acc: 0.0075\n",
            "Epoch 471/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7999 - acc: 0.0086 - val_loss: 3.1834 - val_acc: 0.0067\n",
            "Epoch 472/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6964 - acc: 0.0053 - val_loss: 4.1883 - val_acc: 0.0042\n",
            "Epoch 473/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7817 - acc: 0.0053 - val_loss: 4.0190 - val_acc: 0.0033\n",
            "Epoch 474/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6485 - acc: 0.0057 - val_loss: 5.9004 - val_acc: 0.0042\n",
            "Epoch 475/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7390 - acc: 0.0090 - val_loss: 9.4515 - val_acc: 8.3333e-04\n",
            "Epoch 476/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7611 - acc: 0.0053 - val_loss: 2.3818 - val_acc: 0.0050\n",
            "Epoch 477/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6178 - acc: 0.0070 - val_loss: 4.5308 - val_acc: 0.0042\n",
            "Epoch 478/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8713 - acc: 0.0041 - val_loss: 4.1940 - val_acc: 0.0058\n",
            "Epoch 479/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6297 - acc: 0.0070 - val_loss: 3.0421 - val_acc: 0.0042\n",
            "Epoch 480/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7038 - acc: 0.0066 - val_loss: 5.2627 - val_acc: 8.3333e-04\n",
            "Epoch 481/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6898 - acc: 0.0086 - val_loss: 4.6174 - val_acc: 0.0067\n",
            "Epoch 482/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7431 - acc: 0.0045 - val_loss: 3.9726 - val_acc: 0.0050\n",
            "Epoch 483/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.5415 - acc: 0.0086 - val_loss: 5.8436 - val_acc: 0.0033\n",
            "Epoch 484/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7638 - acc: 0.0041 - val_loss: 12.2721 - val_acc: 0.0000e+00\n",
            "Epoch 485/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7193 - acc: 0.0078 - val_loss: 9.2115 - val_acc: 0.0033\n",
            "Epoch 486/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6735 - acc: 0.0086 - val_loss: 6.0575 - val_acc: 8.3333e-04\n",
            "Epoch 487/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7013 - acc: 0.0103 - val_loss: 2.6888 - val_acc: 0.0025\n",
            "Epoch 488/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8579 - acc: 0.0082 - val_loss: 6.7396 - val_acc: 0.0017\n",
            "Epoch 489/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6998 - acc: 0.0049 - val_loss: 7.4858 - val_acc: 0.0033\n",
            "Epoch 490/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.8548 - acc: 0.0062 - val_loss: 9.6822 - val_acc: 0.0000e+00\n",
            "Epoch 491/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7061 - acc: 0.0094 - val_loss: 3.1850 - val_acc: 0.0067\n",
            "Epoch 492/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.5918 - acc: 0.0066 - val_loss: 2.8777 - val_acc: 0.0042\n",
            "Epoch 493/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7199 - acc: 0.0086 - val_loss: 3.7014 - val_acc: 8.3333e-04\n",
            "Epoch 494/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6703 - acc: 0.0029 - val_loss: 4.9241 - val_acc: 0.0025\n",
            "Epoch 495/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6822 - acc: 0.0049 - val_loss: 8.9746 - val_acc: 8.3333e-04\n",
            "Epoch 496/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6447 - acc: 0.0074 - val_loss: 4.7043 - val_acc: 0.0033\n",
            "Epoch 497/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6220 - acc: 0.0099 - val_loss: 6.5152 - val_acc: 0.0017\n",
            "Epoch 498/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6685 - acc: 0.0070 - val_loss: 12.3405 - val_acc: 8.3333e-04\n",
            "Epoch 499/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.7100 - acc: 0.0078 - val_loss: 5.1418 - val_acc: 0.0017\n",
            "Epoch 500/500\n",
            "2436/2436 [==============================] - 3s 1ms/step - loss: 1.6217 - acc: 0.0094 - val_loss: 4.4170 - val_acc: 0.0025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWkDqj1dA0iw",
        "colab_type": "code",
        "outputId": "1345d545-493d-4ade-d8d3-b11b09a91932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "###########################################\n",
        "# Step 4: Model Prediction\n",
        "#############################################\n",
        "out = neuralNetwork.predict(newTestData[:,:2])\n",
        "print(out)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5001.1714]\n",
            " [6076.9854]\n",
            " [6462.7324]\n",
            " [6657.912 ]\n",
            " [7011.3906]\n",
            " [7118.674 ]\n",
            " [7211.494 ]\n",
            " [7344.077 ]\n",
            " [7456.4434]\n",
            " [7570.5435]\n",
            " [7054.5913]\n",
            " [7628.1304]\n",
            " [7810.2476]\n",
            " [7929.7544]\n",
            " [8051.0894]\n",
            " [6532.3125]\n",
            " [7462.17  ]\n",
            " [8068.845 ]\n",
            " [8306.009 ]\n",
            " [8433.101 ]\n",
            " [8562.146 ]\n",
            " [5339.2217]\n",
            " [7020.49  ]\n",
            " [7893.289 ]\n",
            " [8535.022 ]\n",
            " [8833.247 ]\n",
            " [8968.406 ]\n",
            " [9144.037 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsDwXVAABHDF",
        "colab_type": "code",
        "outputId": "10c380d3-f4d9-4858-eb33-ff7224d09bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#################################\n",
        "# Step 5 : Reserve calculation\n",
        "#################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#print(' Test Data',test_data)\n",
        "#print('pred', model.predict([2,]))\n",
        "#print('C',C)\n",
        "true_reserve = 0\n",
        "for i in range(1,np.shape(triangle)[0]):\n",
        "    j = np.shape(triangle)[1]-1-i\n",
        "    #print(i,j)\n",
        "    #print('last known',C[i,j])\n",
        "    #print(' last estimate',C[i,np.shape(triangle)[1]-1])\n",
        "    true_reserve += (C[i,np.shape(triangle)[1]-1] - C[i,j])\n",
        "    #print(true_reserve)\n",
        "print(\" True reserve\",true_reserve)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " True reserve 17352.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ3X4QakBct6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "appended= np.array(list(zip(test_data,np.ravel(out))))\n",
        "len(appended)\n",
        "\n",
        "out_dict = {}\n",
        "for i in range(len(appended)):\n",
        "    #print(tuple(appended[i,0][:2]))\n",
        "    #print(appended[i,1])\n",
        "    out_dict[tuple(appended[i,0][:2])] = appended[i,1]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wQkKmhECMvg",
        "colab_type": "code",
        "outputId": "dcca0e91-8a44-4bc7-c6f7-c847248ae5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "appended[0,0][:2]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 7.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUQKDOqqBkGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_reserve = 0\n",
        "final_pred = []\n",
        "actuals = []\n",
        "for i in range(1,np.shape(triangle)[0]):\n",
        "    j = int(np.shape(triangle)[1]-1-i)    \n",
        "    #print(i,j)\n",
        "    #print('last known',C[i,j])\n",
        "    #print(' last pred', out_dict[(i,np.shape(triangle)[1]-1)])\n",
        "    #print(' last estimate',C[i,np.shape(triangle)[1]-1])\n",
        "    final_pred.append(out_dict[(i,np.shape(triangle)[1]-1)] - C[i,j])\n",
        "    actuals.append(C[i,np.shape(triangle)[1]-1] - C[i,j])\n",
        "    pred_reserve +=(out_dict[(i,np.shape(triangle)[1]-1)] - C[i,j])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsYABGSNBq_7",
        "colab_type": "code",
        "outputId": "2d9d6033-e9c9-497d-f989-527d735c050d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\" Predicted reserve\",pred_reserve)\n",
        "print(' Bias',pred_reserve - true_reserve)\n",
        "print('Bias pct',(pred_reserve-true_reserve)/true_reserve)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Predicted reserve 13750.39404296875\n",
            " Bias -3601.60595703125\n",
            "Bias pct -0.20756143136417993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bLrRyChBv7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "fa4d61b6-48de-49b2-d4a5-29684d291552"
      },
      "source": [
        "#ploting the loss of Neural Network\n",
        "from matplotlib import pyplot\n",
        "\n",
        "#training loss and validation loss\n",
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.plot(history.history['val_loss'])\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.legend(['train','validation'],loc='upper right')\n",
        "pyplot.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJFo1AREZGi+f9CR7dDvK23NwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIJE88AV9PWH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "d90d6095-0fa9-4932-8889-4927253c5204"
      },
      "source": [
        "#plot showing predicted value vs actual value\n",
        "plt.figure()\n",
        "plt.plot(actuals, label = \"Test Originals\")\n",
        "plt.plot(final_pred, label =\"Test Predictions\")\n",
        "plt.ylabel(\"Reserve Value\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "infjaZWG-725",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0414ec6-8b6e-4ec2-c710-f60322ac30fc"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFXoRgKh_1Np",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c7b0010-cdab-4748-ff07-2f8cc70f3a4e"
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psT4A56C_5AJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3af90e29-c630-461c-f754-c06982a3edbb"
      },
      "source": [
        "type(test_data)\n",
        "type(out)\n",
        "out"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te7QmCDDAVYQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "1c26a92f-71cf-4bea-9c70-e2b1de728ffb"
      },
      "source": [
        "#plot for the predicted and the test lower triangle\n",
        "plt.plot(test_data[:,2],label='Test Value')\n",
        "plt.plot(out,label='Predicted Value')\n",
        "plt.legend()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1e6c1907f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvaL4bpsA59N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}